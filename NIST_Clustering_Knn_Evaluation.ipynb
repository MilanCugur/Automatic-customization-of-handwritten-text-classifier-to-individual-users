{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NIST_Clustering_Knn_Evaluation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MilanCugur/Offline_Writer_Identification/blob/master/NIST_Clustering_Knn_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "na2fyD9uQj0U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up ImageDisk and Info Disk"
      ]
    },
    {
      "metadata": {
        "id": "QzrIME0_QTsi",
        "colab_type": "code",
        "outputId": "55dd4a03-2142-4741-c949-89146fde9ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BY88VXhSQnZd",
        "colab_type": "code",
        "outputId": "cc165741-6c84-44db-cc4b-cb826be61a56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "\n",
        "from keras.utils import Sequence\n",
        "from random import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "efkriK-nQyE5",
        "colab_type": "code",
        "outputId": "81412a4e-983d-4e53-8364-d3edf40fc9b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Extract images to './ImageDisk' folder\n",
        "\n",
        "path = './drive/My Drive/New_Approach_29.12.2018/ImageDisk.zip'  # Different .zip folder with images\n",
        "archive = ZipFile(path, 'r')\n",
        "archive.extractall('./ImageDisk')  \n",
        "archive.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 23s, sys: 41.6 s, total: 2min 4s\n",
            "Wall time: 2min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TR2vOC3OQz1n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract info about the images to InfoDisk list (path, ascii, writer_id); \n",
        "# example: ('f0500_38/l0500_38/l0500_38_00008.png', '106', '500')\n",
        "path = './drive/My Drive/New_Approach_29.12.2018/InfoDisk.txt'  \n",
        "InfoDisk = []\n",
        "\n",
        "with open(path, \"r\") as f:\n",
        "  for line in f.readlines():\n",
        "    line = line.rstrip('\\n').split(' ')\n",
        "    InfoDisk.append((line[0], line[1], line[2]))\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3WUqm5aaRGr3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# OneHot Class"
      ]
    },
    {
      "metadata": {
        "id": "SeaE7YgfQ1Rv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# OneHot Encoding\n",
        "class OneHot():  \n",
        "  # classes = list of classes : 0-9, a-z, A-Z\n",
        "  # n = number of classes     : 62\n",
        "  \n",
        "  def __init__(self, classes):\n",
        "    self.classes = classes\n",
        "    self.n = len(classes)\n",
        "    \n",
        "  def encode(self, class_name):\n",
        "    one_hot = np.zeros(shape=(self.n), dtype=np.int8)\n",
        "    class_index = self.classes.index(class_name)\n",
        "    one_hot[class_index] = 1\n",
        "    return one_hot\n",
        "  \n",
        "  def encode_all(self, list_class_names):\n",
        "    return np.array([self.encode(class_name) for class_name in list_class_names])\n",
        "  \n",
        "  def decode(self, one_hot):\n",
        "    class_index = one_hot.argmax()\n",
        "    return self.classes[class_index]\n",
        "  \n",
        "  def decode_all(self, list_one_hots):\n",
        "    return np.array([self.decode(one_hot) for one_hot in list_one_hots])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WQDnOGoeRNW0",
        "colab_type": "code",
        "outputId": "9ddbbd2c-0651-45cb-dfa2-ecbdfd7b57a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "labels = set()\n",
        "for (path, label, writer) in InfoDisk:\n",
        "  labels.add(label)\n",
        "OH_L = OneHot(sorted(labels))\n",
        "\n",
        "print(sorted(labels))  # 62 ascii codes in string format\n",
        "print(len(labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '97', '98', '99']\n",
            "62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i_UKAH84RVZh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data "
      ]
    },
    {
      "metadata": {
        "id": "u3qymIG-RUm0",
        "colab_type": "code",
        "outputId": "016e4cec-1947-4edc-daa5-249b59934dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "writers = {}\n",
        "for path, label, writer in InfoDisk:\n",
        "  writer = int(writer)\n",
        "  if writer in writers:\n",
        "    writers[writer] += 1\n",
        "  else:\n",
        "    writers[writer] = 1\n",
        "  \n",
        "writers = list(writers.items())\n",
        "writers = sorted(writers, key=lambda x: x[1])  # sort writers with respect to number of characters they wrote\n",
        "print(writers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1727, 18), (825, 21), (1725, 24), (1965, 30), (2027, 33), (1726, 39), (2046, 40), (2044, 41), (1995, 43), (1990, 46), (1992, 46), (1984, 49), (1974, 49), (1767, 50), (1723, 51), (1969, 51), (1556, 67), (1756, 67), (2067, 72), (1110, 76), (4043, 77), (1977, 79), (1209, 79), (1749, 86), (1006, 86), (1731, 87), (2504, 90), (2097, 91), (1598, 92), (3704, 92), (3901, 94), (1931, 95), (416, 95), (1348, 95), (1831, 97), (3642, 98), (1016, 98), (1280, 99), (1854, 99), (1675, 100), (1923, 100), (3696, 102), (1621, 102), (1733, 102), (2105, 102), (1576, 103), (1432, 103), (1783, 103), (3797, 103), (1542, 103), (2048, 104), (1607, 105), (2095, 105), (785, 105), (2069, 106), (1919, 106), (1646, 107), (2047, 107), (2077, 107), (1517, 107), (1523, 107), (1386, 107), (4064, 107), (1859, 107), (2040, 107), (1548, 108), (3240, 108), (3820, 108), (3747, 108), (1802, 108), (1944, 109), (1639, 109), (2032, 109), (1788, 110), (1671, 111), (1686, 112), (3296, 112), (2099, 112), (2080, 113), (1655, 113), (1502, 113), (1615, 113), (3254, 114), (1918, 114), (1005, 114), (1914, 115), (2056, 115), (2177, 115), (2421, 115), (790, 115), (1754, 115), (2329, 116), (1872, 116), (1476, 116), (1967, 116), (2344, 117), (1816, 117), (1674, 118), (1716, 118), (1899, 118), (1828, 118), (1513, 118), (1102, 118), (2443, 119), (1665, 119), (1866, 119), (1772, 119), (2070, 120), (1578, 120), (1163, 120), (1835, 121), (1509, 122), (2063, 122), (1858, 122), (1850, 123), (1911, 123), (2559, 124), (2007, 124), (3705, 124), (1780, 125), (1786, 125), (3720, 125), (2153, 125), (2549, 125), (1302, 125), (1982, 125), (969, 125), (3566, 125), (1573, 126), (1549, 126), (1100, 126), (1829, 127), (1876, 127), (1975, 127), (2225, 127), (1580, 128), (1759, 128), (1771, 128), (2031, 128), (1503, 128), (1570, 128), (1789, 128), (1743, 129), (1794, 129), (1898, 129), (1915, 129), (1966, 129), (2145, 129), (1672, 129), (1793, 129), (1808, 129), (1747, 130), (1928, 130), (1384, 130), (1868, 130), (48, 131), (1958, 131), (1261, 131), (1495, 131), (2232, 131), (1687, 132), (1782, 132), (3920, 132), (2349, 132), (2034, 132), (3784, 132), (294, 132), (2583, 132), (2422, 133), (1508, 133), (2043, 133), (2487, 133), (1531, 133), (1636, 133), (2309, 133), (1860, 133), (2094, 133), (2005, 133), (2158, 134), (1882, 134), (2028, 134), (4022, 134), (2137, 134), (1809, 134), (3606, 134), (3944, 134), (3995, 134), (1980, 134), (2589, 135), (1961, 135), (1804, 135), (1857, 135), (1869, 135), (3929, 135), (3992, 135), (1851, 135), (3363, 135), (2248, 135), (1979, 135), (1878, 136), (2023, 136), (2062, 136), (1972, 136), (1269, 136), (3636, 136), (2169, 137), (2331, 137), (1594, 137), (1888, 137), (1140, 137), (1297, 137), (2449, 137), (1777, 137), (1221, 137), (2249, 137), (3613, 137), (4050, 137), (4085, 137), (2090, 138), (2202, 138), (2478, 138), (1717, 138), (1745, 138), (2009, 138), (3538, 138), (1935, 138), (1939, 138), (2278, 139), (1512, 139), (1553, 139), (1623, 139), (1711, 139), (1811, 139), (1814, 139), (1867, 139), (1909, 139), (2136, 139), (1881, 139), (1887, 139), (1934, 139), (1499, 139), (3882, 139), (4074, 139), (2575, 139), (2215, 140), (1552, 140), (3223, 140), (1981, 140), (3833, 140), (2400, 140), (4093, 140), (2139, 141), (1592, 141), (1707, 141), (1713, 141), (2074, 141), (2197, 141), (3556, 141), (2489, 141), (2524, 141), (4086, 141), (3457, 141), (582, 142), (2149, 142), (1500, 142), (1545, 142), (1737, 142), (1790, 142), (3180, 142), (2199, 142), (1603, 142), (1751, 142), (3291, 142), (2206, 143), (2251, 143), (1877, 143), (1913, 143), (1959, 143), (1983, 143), (2439, 143), (2599, 143), (1668, 143), (3519, 143), (4094, 143), (4090, 143), (1518, 144), (1620, 144), (1657, 144), (1666, 144), (1764, 144), (1937, 144), (1938, 144), (1949, 144), (3172, 144), (1018, 144), (2553, 144), (2029, 144), (3409, 144), (4097, 144), (1891, 144), (1903, 144), (3626, 144), (2295, 145), (2598, 145), (1538, 145), (1563, 145), (1797, 145), (1880, 145), (2061, 145), (2121, 145), (2254, 145), (1818, 145), (1843, 145), (3595, 145), (1641, 146), (1653, 146), (1798, 146), (1893, 146), (2039, 146), (1358, 146), (2152, 146), (2218, 146), (1879, 146), (1932, 146), (3245, 146), (4098, 146), (2205, 146), (4087, 146), (3559, 146), (2187, 147), (2456, 147), (1504, 147), (1558, 147), (1593, 147), (1673, 147), (1839, 147), (1946, 147), (1973, 147), (3269, 147), (1521, 147), (1637, 147), (1952, 147), (2049, 147), (3175, 147), (3819, 147), (3888, 147), (3967, 147), (2170, 147), (2207, 147), (3810, 147), (3866, 147), (2120, 148), (2165, 148), (2247, 148), (2307, 148), (2373, 148), (2592, 148), (1537, 148), (1596, 148), (1823, 148), (2020, 148), (2089, 148), (1389, 148), (3842, 148), (2101, 148), (1825, 148), (3472, 148), (3632, 148), (837, 149), (848, 149), (2108, 149), (2486, 149), (2491, 149), (1507, 149), (1599, 149), (1685, 149), (1691, 149), (1736, 149), (1865, 149), (1873, 149), (1902, 149), (2058, 149), (3262, 149), (3512, 149), (3813, 149), (1746, 149), (1796, 149), (1838, 149), (2024, 149), (2057, 149), (3574, 149), (3602, 149), (4092, 149), (2175, 149), (3551, 149), (2431, 150), (2480, 150), (1505, 150), (1597, 150), (1626, 150), (1696, 150), (1706, 150), (1708, 150), (1787, 150), (1805, 150), (1813, 150), (2002, 150), (1228, 150), (1410, 150), (2260, 150), (2426, 150), (1648, 150), (3796, 150), (4053, 150), (2117, 150), (2171, 150), (3715, 150), (2304, 151), (1011, 151), (2230, 151), (1606, 151), (3381, 151), (3573, 151), (3661, 151), (3742, 151), (3800, 151), (4079, 151), (2367, 151), (3572, 151), (1506, 152), (1642, 152), (1922, 152), (2220, 152), (2267, 152), (1664, 152), (1901, 152), (2015, 152), (2079, 152), (3278, 152), (3515, 152), (3537, 152), (3607, 152), (3826, 152), (3839, 152), (3904, 152), (4048, 152), (4054, 152), (3793, 152), (3999, 152), (2236, 153), (2441, 153), (2564, 153), (1529, 153), (1663, 153), (1734, 153), (1834, 153), (1924, 153), (1926, 153), (3451, 153), (3681, 153), (3731, 153), (2151, 153), (1611, 153), (1770, 153), (1948, 153), (1989, 153), (2011, 153), (2054, 153), (3426, 153), (3645, 153), (3760, 153), (1778, 153), (2366, 154), (2381, 154), (2434, 154), (2472, 154), (1587, 154), (1628, 154), (1632, 154), (1677, 154), (1761, 154), (1781, 154), (1832, 154), (1856, 154), (1988, 154), (2037, 154), (2065, 154), (1419, 154), (3931, 154), (2271, 154), (2282, 154), (2440, 154), (1659, 154), (1660, 154), (1894, 154), (2004, 154), (2008, 154), (3635, 154), (3726, 154), (2436, 154), (937, 155), (2128, 155), (2134, 155), (2266, 155), (1564, 155), (1625, 155), (1650, 155), (1846, 155), (1955, 155), (3149, 155), (3317, 155), (3377, 155), (3664, 155), (3794, 155), (4058, 155), (4068, 155), (2124, 155), (2219, 155), (2364, 155), (1516, 155), (1535, 155), (1769, 155), (1896, 155), (2078, 155), (2087, 155), (3239, 155), (3301, 155), (3339, 155), (4030, 155), (2302, 155), (2558, 155), (1697, 155), (1784, 155), (3785, 155), (3462, 155), (2270, 156), (2317, 156), (2597, 156), (1577, 156), (1755, 156), (1844, 156), (2013, 156), (3181, 156), (1036, 156), (4051, 156), (2133, 156), (2288, 156), (2565, 156), (1680, 156), (1710, 156), (1763, 156), (1863, 156), (1905, 156), (1940, 156), (3257, 156), (3694, 156), (3711, 156), (3881, 156), (3996, 156), (4017, 156), (2168, 156), (3983, 156), (247, 156), (1699, 156), (2126, 157), (2229, 157), (2338, 157), (2390, 157), (2463, 157), (2500, 157), (1581, 157), (1701, 157), (1803, 157), (1819, 157), (1904, 157), (1910, 157), (2006, 157), (3619, 157), (3856, 157), (4083, 157), (1826, 157), (1847, 157), (1957, 157), (2041, 157), (2064, 157), (3237, 157), (3242, 157), (3478, 157), (3660, 157), (3703, 157), (3762, 157), (4008, 157), (2243, 157), (2415, 157), (1773, 157), (346, 158), (2176, 158), (2227, 158), (2505, 158), (1624, 158), (1634, 158), (1703, 158), (1760, 158), (2050, 158), (2055, 158), (3545, 158), (3741, 158), (2312, 158), (2316, 158), (2327, 158), (2330, 158), (1586, 158), (2030, 158), (2038, 158), (2083, 158), (3319, 158), (3617, 158), (3803, 158), (4044, 158), (2081, 158), (3623, 158), (2192, 159), (2276, 159), (2452, 159), (2499, 159), (1554, 159), (1569, 159), (1595, 159), (1694, 159), (1698, 159), (1724, 159), (1871, 159), (1929, 159), (1991, 159), (2018, 159), (2084, 159), (3182, 159), (3226, 159), (3334, 159), (3489, 159), (3650, 159), (3653, 159), (4003, 159), (4070, 159), (2154, 159), (2162, 159), (2347, 159), (2362, 159), (2539, 159), (1561, 159), (1658, 159), (1807, 159), (3295, 159), (3550, 159), (1037, 159), (1388, 159), (1404, 159), (3691, 159), (3740, 159), (3802, 159), (2286, 159), (3658, 159), (3880, 159), (1933, 159), (2231, 160), (2238, 160), (1501, 160), (1524, 160), (1661, 160), (1718, 160), (1730, 160), (1741, 160), (1757, 160), (1824, 160), (1971, 160), (1985, 160), (1987, 160), (2016, 160), (2072, 160), (3255, 160), (3353, 160), (3418, 160), (3656, 160), (3739, 160), (4046, 160), (2435, 160), (1827, 160), (1947, 160), (1994, 160), (3384, 160), (3490, 160), (3830, 160), (3855, 160), (3980, 160), (3506, 160), (2107, 161), (2163, 161), (2212, 161), (2256, 161), (2385, 161), (2506, 161), (1735, 161), (1766, 161), (1830, 161), (1848, 161), (1864, 161), (1925, 161), (1943, 161), (2075, 161), (3167, 161), (3312, 161), (3350, 161), (3599, 161), (3934, 161), (2300, 161), (2310, 161), (2352, 161), (2563, 161), (1612, 161), (1682, 161), (1688, 161), (3129, 161), (3287, 161), (3340, 161), (3525, 161), (3659, 161), (3922, 161), (3948, 161), (3964, 161), (3965, 161), (4009, 161), (2275, 161), (4039, 161), (363, 161), (2203, 161), (2408, 162), (2445, 162), (2550, 162), (1526, 162), (1562, 162), (1591, 162), (1609, 162), (1692, 162), (1719, 162), (1776, 162), (1817, 162), (1890, 162), (1892, 162), (1964, 162), (3116, 162), (3121, 162), (1105, 162), (3728, 162), (3761, 162), (3766, 162), (4084, 162), (2132, 162), (2150, 162), (2314, 162), (2372, 162), (2554, 162), (1883, 162), (3236, 162), (3284, 162), (3307, 162), (3393, 162), (3424, 162), (3565, 162), (3693, 162), (3791, 162), (4010, 162), (4091, 162), (2195, 162), (2360, 162), (2003, 162), (3272, 162), (2397, 162), (2188, 163), (2208, 163), (2211, 163), (2306, 163), (2321, 163), (2379, 163), (2403, 163), (2438, 163), (2464, 163), (2521, 163), (2556, 163), (1600, 163), (1821, 163), (1886, 163), (1920, 163), (1976, 163), (2053, 163), (3146, 163), (3509, 163), (3571, 163), (1179, 163), (3792, 163), (3846, 163), (3956, 163), (2127, 163), (2492, 163), (2590, 163), (1614, 163), (1638, 163), (1656, 163), (1779, 163), (1996, 163), (2096, 163), (2098, 163), (3244, 163), (3423, 163), (3496, 163), (3521, 163), (1322, 163), (3640, 163), (3863, 163), (3893, 163), (1714, 163), (2115, 164), (2196, 164), (2265, 164), (2272, 164), (2274, 164), (2334, 164), (2357, 164), (2384, 164), (2444, 164), (2488, 164), (2546, 164), (2596, 164), (1532, 164), (1618, 164), (1667, 164), (1700, 164), (1785, 164), (1791, 164), (1822, 164), (1845, 164), (1927, 164), (1956, 164), (1962, 164), (1978, 164), (1997, 164), (2001, 164), (2021, 164), (3105, 164), (3112, 164), (3542, 164), (3763, 164), (3812, 164), (2102, 164), (2246, 164), (2502, 164), (1557, 164), (1986, 164), (2014, 164), (3204, 164), (3224, 164), (3233, 164), (3293, 164), (3465, 164), (3666, 164), (3851, 164), (3896, 164), (2182, 164), (1514, 164), (2146, 165), (2365, 165), (2395, 165), (2437, 165), (2533, 165), (2552, 165), (1588, 165), (1589, 165), (1590, 165), (1852, 165), (1908, 165), (2012, 165), (2025, 165), (2042, 165), (2068, 165), (3114, 165), (3119, 165), (3575, 165), (3698, 165), (3699, 165), (3982, 165), (3988, 165), (4015, 165), (4027, 165), (4063, 165), (1652, 165), (1693, 165), (1758, 165), (1907, 165), (3179, 165), (3202, 165), (3315, 165), (3652, 165), (4014, 165), (4038, 165), (4071, 165), (4082, 165), (2209, 165), (2250, 165), (3412, 165), (3795, 165), (3894, 165), (579, 166), (2109, 166), (2280, 166), (2359, 166), (2567, 166), (2580, 166), (1522, 166), (1525, 166), (1568, 166), (1604, 166), (1669, 166), (1800, 166), (1810, 166), (1970, 166), (2019, 166), (3151, 166), (3316, 166), (3344, 166), (3413, 166), (3435, 166), (3517, 166), (3544, 166), (3594, 166), (3604, 166), (3825, 166), (3854, 166), (3941, 166), (4095, 166), (2328, 166), (2356, 166), (2386, 166), (2544, 166), (1608, 166), (1695, 166), (3157, 166), (3195, 166), (3310, 166), (3436, 166), (3531, 166), (3641, 166), (3647, 166), (3770, 166), (3778, 166), (3878, 166), (3978, 166), (2332, 166), (2337, 166), (2588, 166), (3630, 166), (3643, 166), (4042, 166), (4077, 166), (2262, 166), (2293, 167), (2299, 167), (2350, 167), (2433, 167), (2460, 167), (2518, 167), (1543, 167), (1555, 167), (1605, 167), (1622, 167), (1853, 167), (3104, 167), (3256, 167), (3292, 167), (3399, 167), (3557, 167), (1092, 167), (3738, 167), (3827, 167), (3829, 167), (3903, 167), (2140, 167), (2173, 167), (2222, 167), (2239, 167), (2252, 167), (2297, 167), (2333, 167), (2447, 167), (2450, 167), (2542, 167), (2593, 167), (1511, 167), (1519, 167), (1550, 167), (1619, 167), (1720, 167), (1765, 167), (1950, 167), (3338, 167), (3497, 167), (3562, 167), (3671, 167), (3776, 167), (3798, 167), (3808, 167), (3905, 167), (3913, 167), (3923, 167), (3932, 167), (4023, 167), (4052, 167), (4061, 167), (4065, 167), (2200, 167), (2529, 167), (3206, 167), (3346, 167), (3817, 167), (3867, 167), (2157, 168), (2161, 168), (2346, 168), (2398, 168), (2410, 168), (2416, 168), (2528, 168), (1566, 168), (1582, 168), (1602, 168), (1684, 168), (1768, 168), (1820, 168), (1842, 168), (1884, 168), (1912, 168), (2035, 168), (2060, 168), (2082, 168), (2086, 168), (3186, 168), (3189, 168), (3231, 168), (3246, 168), (3487, 168), (3523, 168), (1377, 168), (3646, 168), (3670, 168), (3690, 168), (3769, 168), (3870, 168), (3909, 168), (3915, 168), (3938, 168), (3940, 168), (3961, 168), (2318, 168), (2451, 168), (2571, 168), (1547, 168), (1584, 168), (1840, 168), (2076, 168), (3221, 168), (3270, 168), (3308, 168), (3311, 168), (3441, 168), (3688, 168), (3714, 168), (3737, 168), (3788, 168), (3910, 168), (3997, 168), (3998, 168), (4089, 168), (2235, 168), (3534, 168), (3620, 168), (3735, 168), (3907, 168), (3482, 168), (1056, 168), (2174, 169), (2244, 169), (2269, 169), (2405, 169), (2466, 169), (2483, 169), (2508, 169), (2560, 169), (2585, 169), (1541, 169), (1544, 169), (1585, 169), (1640, 169), (1679, 169), (1690, 169), (1709, 169), (1729, 169), (1849, 169), (1993, 169), (2017, 169), (2091, 169), (3222, 169), (3336, 169), (3452, 169), (3464, 169), (3471, 169), (1346, 169), (3616, 169), (3655, 169), (3759, 169), (3789, 169), (3950, 169), (4033, 169), (2138, 169), (2257, 169), (2285, 169), (2315, 169), (2324, 169), (2325, 169), (2380, 169), (2461, 169), (2496, 169), (2507, 169), (2582, 169), (1815, 169), (1900, 169), (3235, 169), (3348, 169), (3358, 169), (3406, 169), (3422, 169), (3425, 169), (3547, 169), (3665, 169), (3889, 169), (3972, 169), (3994, 169), (4019, 169), (2348, 169), (1299, 169), (3663, 169), (3702, 169), (3928, 169), (3979, 169), (4060, 169), (2296, 170), (2342, 170), (2353, 170), (2387, 170), (2399, 170), (2404, 170), (2407, 170), (2442, 170), (2469, 170), (2490, 170), (2503, 170), (1560, 170), (1610, 170), (1670, 170), (1683, 170), (1916, 170), (2051, 170), (2059, 170), (2088, 170), (2093, 170), (3113, 170), (3115, 170), (3185, 170), (3378, 170), (1202, 170), (3689, 170), (3806, 170), (3845, 170), (3877, 170), (3884, 170), (3937, 170), (4032, 170), (2123, 170), (2159, 170), (2240, 170), (2294, 170), (2371, 170), (2396, 170), (2427, 170), (2482, 170), (2572, 170), (2587, 170), (1740, 170), (1753, 170), (1861, 170), (1945, 170), (2092, 170), (3178, 170), (3251, 170), (3282, 170), (3320, 170), (3448, 170), (3463, 170), (3476, 170), (3526, 170), (3570, 170), (3586, 170), (3596, 170), (1154, 170), (3618, 170), (3624, 170), (3725, 170), (3727, 170), (3754, 170), (3755, 170), (3767, 170), (3786, 170), (3849, 170), (4069, 170), (2264, 170), (2389, 170), (3125, 170), (3200, 170), (3216, 170), (3306, 170), (3397, 170), (740, 171), (2155, 171), (2156, 171), (2186, 171), (2189, 171), (2283, 171), (2292, 171), (2319, 171), (2418, 171), (2424, 171), (2493, 171), (2526, 171), (2531, 171), (2574, 171), (1565, 171), (1635, 171), (1643, 171), (1681, 171), (1762, 171), (1795, 171), (2033, 171), (3148, 171), (3208, 171), (3359, 171), (3389, 171), (3432, 171), (3442, 171), (3536, 171), (3584, 171), (3622, 171), (3724, 171), (3743, 171), (3745, 171), (3787, 171), (3860, 171), (3952, 171), (2141, 171), (2167, 171), (2241, 171), (2259, 171), (2545, 171), (1715, 171), (2026, 171), (3154, 171), (3205, 171), (3335, 171), (3398, 171), (3403, 171), (3455, 171), (3558, 171), (1146, 171), (3628, 171), (3644, 171), (3669, 171), (3677, 171), (3730, 171), (3774, 171), (3874, 171), (3886, 171), (3936, 171), (4012, 171), (2194, 171), (3369, 171), (3485, 171), (2116, 172), (2118, 172), (2233, 172), (2261, 172), (2368, 172), (2377, 172), (2378, 172), (2411, 172), (2417, 172), (2423, 172), (2453, 172), (2475, 172), (2479, 172), (2513, 172), (2547, 172), (1579, 172), (1617, 172), (1631, 172), (1633, 172), (1654, 172), (1678, 172), (1732, 172), (1862, 172), (1921, 172), (1936, 172), (1968, 172), (1998, 172), (1999, 172), (2010, 172), (2066, 172), (3131, 172), (3188, 172), (3190, 172), (3201, 172), (3313, 172), (3328, 172), (3388, 172), (3408, 172), (3443, 172), (3507, 172), (3553, 172), (3625, 172), (3629, 172), (3637, 172), (3713, 172), (3781, 172), (3821, 172), (3831, 172), (3844, 172), (3853, 172), (3868, 172), (3924, 172), (3935, 172), (3957, 172), (2111, 172), (2289, 172), (2358, 172), (2455, 172), (2516, 172), (2535, 172), (2570, 172), (2595, 172), (1613, 172), (1752, 172), (1906, 172), (3211, 172), (3232, 172), (3266, 172), (3349, 172), (3414, 172), (3417, 172), (3467, 172), (3561, 172), (3592, 172), (3631, 172), (3648, 172), (3991, 172), (4035, 172), (4045, 172), (2114, 172), (2184, 172), (2515, 172), (3176, 172), (3191, 172), (3309, 172), (3385, 172), (3687, 172), (3875, 172), (3433, 172), (2183, 173), (2221, 173), (2298, 173), (2320, 173), (2363, 173), (2388, 173), (2471, 173), (2498, 173), (2541, 173), (2548, 173), (2557, 173), (1510, 173), (1567, 173), (1689, 173), (1792, 173), (1812, 173), (1870, 173), (1874, 173), (3101, 173), (3173, 173), (3357, 173), (3446, 173), (3488, 173), (3499, 173), (3546, 173), (3634, 173), (3657, 173), (3682, 173), (3921, 173), (3962, 173), (3989, 173), (4028, 173), (2181, 173), (2201, 173), (2210, 173), (2287, 173), (2391, 173), (2425, 173), (1627, 173), (3107, 173), (3153, 173), (3376, 173), (3568, 173), (3804, 173), (3816, 173), (3859, 173), (3897, 173), (3930, 173), (3971, 173), (3984, 173), (4024, 173), (4037, 173), (4059, 173), (4080, 173), (4099, 173), (2216, 173), (2468, 173), (3260, 173), (3326, 173), (2125, 174), (2462, 174), (2494, 174), (2509, 174), (2522, 174), (2525, 174), (2534, 174), (2543, 174), (1530, 174), (1616, 174), (1630, 174), (1676, 174), (1738, 174), (1744, 174), (1774, 174), (1801, 174), (1841, 174), (1885, 174), (1917, 174), (2073, 174), (3100, 174), (3139, 174), (3140, 174), (3207, 174), (3267, 174), (3268, 174), (3281, 174), (3314, 174), (3368, 174), (3372, 174), (3474, 174), (3782, 174), (3857, 174), (3925, 174), (3926, 174), (3953, 174), (3966, 174), (3981, 174), (2277, 174), (2284, 174), (2311, 174), (2361, 174), (2383, 174), (2412, 174), (2576, 174), (1546, 174), (1601, 174), (1895, 174), (1897, 174), (2045, 174), (3120, 174), (3166, 174), (3273, 174), (3297, 174), (3484, 174), (3540, 174), (3554, 174), (3591, 174), (3601, 174), (3603, 174), (3651, 174), (3662, 174), (3676, 174), (3701, 174), (3748, 174), (3815, 174), (3818, 174), (3917, 174), (3927, 174), (3946, 174), (4016, 174), (4031, 174), (4040, 174), (2253, 174), (2459, 174), (2172, 175), (2228, 175), (2245, 175), (2313, 175), (2323, 175), (2343, 175), (2481, 175), (2484, 175), (2495, 175), (2510, 175), (2512, 175), (2517, 175), (2519, 175), (2523, 175), (2568, 175), (1520, 175), (1528, 175), (1539, 175), (1551, 175), (1629, 175), (1702, 175), (1712, 175), (1722, 175), (1742, 175), (1954, 175), (1960, 175), (2085, 175), (3141, 175), (3156, 175), (3160, 175), (3214, 175), (3330, 175), (3332, 175), (3366, 175), (3407, 175), (3470, 175), (3498, 175), (3510, 175), (3511, 175), (3516, 175), (3564, 175), (3569, 175), (3612, 175), (3707, 175), (3710, 175), (3764, 175), (3777, 175), (3835, 175), (3900, 175), (3911, 175), (3973, 175), (4055, 175), (4057, 175), (4072, 175), (4096, 175), (2143, 175), (2160, 175), (2180, 175), (2234, 175), (2301, 175), (2428, 175), (1704, 175), (1721, 175), (1951, 175), (1953, 175), (3227, 175), (3318, 175), (3481, 175), (3530, 175), (3541, 175), (3567, 175), (3590, 175), (1347, 175), (3614, 175), (3683, 175), (3734, 175), (3749, 175), (3758, 175), (3799, 175), (3801, 175), (3852, 175), (3864, 175), (3947, 175), (2339, 175), (2551, 175), (2586, 175), (4029, 175), (857, 176), (2103, 176), (2142, 176), (2144, 176), (2147, 176), (2166, 176), (2179, 176), (2273, 176), (2290, 176), (2354, 176), (2370, 176), (2393, 176), (2454, 176), (2501, 176), (2537, 176), (2579, 176), (1515, 176), (1533, 176), (1647, 176), (1662, 176), (1750, 176), (1775, 176), (1806, 176), (1836, 176), (1855, 176), (2000, 176), (3106, 176), (3109, 176), (3132, 176), (3155, 176), (3170, 176), (3215, 176), (3238, 176), (3261, 176), (3271, 176), (3294, 176), (3323, 176), (3374, 176), (3440, 176), (3469, 176), (3480, 176), (3483, 176), (3513, 176), (3528, 176), (3533, 176), (3610, 176), (3633, 176), (3679, 176), (3746, 176), (3871, 176), (3916, 176), (3986, 176), (3990, 176), (4078, 176), (2204, 176), (2322, 176), (2355, 176), (2401, 176), (2413, 176), (2419, 176), (2514, 176), (2577, 176), (2578, 176), (1540, 176), (1889, 176), (3161, 176), (3405, 176), (3410, 176), (3445, 176), (3539, 176), (3654, 176), (3744, 176), (3837, 176), (3899, 176), (3949, 176), (3955, 176), (3975, 176), (4034, 176), (4073, 176), (2335, 176), (3168, 176), (3184, 176), (3750, 176), (4006, 176), (428, 176), (2112, 177), (2119, 177), (2129, 177), (2148, 177), (2242, 177), (2308, 177), (2336, 177), (2345, 177), (2351, 177), (2430, 177), (2458, 177), (2527, 177), (2562, 177), (2566, 177), (2569, 177), (2581, 177), (1534, 177), (1574, 177), (1645, 177), (1728, 177), (1799, 177), (1837, 177), (1930, 177), (2071, 177), (3130, 177), (3134, 177), (3234, 177), (3241, 177), (3277, 177), (3298, 177), (3352, 177), (3360, 177), (3361, 177), (3362, 177), (3364, 177), (3367, 177), (3373, 177), (3387, 177), (3450, 177), (3468, 177), (3500, 177), (3638, 177), (3709, 177), (3805, 177), (3869, 177), (3879, 177), (3968, 177), (3969, 177), (3985, 177), (426, 177), (2106, 177), (2135, 177), (2193, 177), (2223, 177), (2369, 177), (2394, 177), (2409, 177), (2448, 177), (2485, 177), (1963, 177), (3122, 177), (3138, 177), (3171, 177), (3243, 177), (3250, 177), (3286, 177), (3302, 177), (3486, 177), (3514, 177), (3535, 177), (1234, 177), (3600, 177), (3675, 177), (3717, 177), (3719, 177), (3723, 177), (3753, 177), (3768, 177), (3773, 177), (3775, 177), (3841, 177), (3847, 177), (3850, 177), (3908, 177), (3974, 177), (4066, 177), (4088, 177), (3258, 177), (3380, 177), (3756, 177), (213, 178), (2100, 178), (2237, 178), (2326, 178), (2340, 178), (2382, 178), (2429, 178), (2467, 178), (2476, 178), (2520, 178), (2536, 178), (2594, 178), (1536, 178), (1649, 178), (1748, 178), (1833, 178), (1875, 178), (2022, 178), (2036, 178), (3159, 178), (3187, 178), (3199, 178), (3218, 178), (3219, 178), (3220, 178), (3229, 178), (3263, 178), (3264, 178), (3279, 178), (3303, 178), (3325, 178), (3329, 178), (3343, 178), (3347, 178), (3400, 178), (3404, 178), (3428, 178), (3438, 178), (3475, 178), (3491, 178), (3529, 178), (3543, 178), (3548, 178), (1128, 178), (1232, 178), (1271, 178), (3718, 178), (3732, 178), (3779, 178), (3780, 178), (3809, 178), (3883, 178), (3891, 178), (3919, 178), (4076, 178), (2305, 178), (2375, 178), (1644, 178), (1705, 178), (1739, 178), (3126, 178), (3128, 178), (3136, 178), (3192, 178), (3203, 178), (3331, 178), (3560, 178), (3582, 178), (3672, 178), (3673, 178), (3700, 178), (3895, 178), (3898, 178), (3902, 178), (3912, 178), (3933, 178), (3976, 178), (4001, 178), (4036, 178), (4062, 178), (2213, 178), (2573, 178), (3580, 178), (3721, 178), (2130, 179), (2131, 179), (2164, 179), (2190, 179), (2191, 179), (2198, 179), (2263, 179), (2341, 179), (2392, 179), (2446, 179), (2474, 179), (2497, 179), (1527, 179), (1559, 179), (1651, 179), (2052, 179), (3102, 179), (3111, 179), (3137, 179), (3142, 179), (3163, 179), (3225, 179), (3247, 179), (3259, 179), (3285, 179), (3300, 179), (3341, 179), (3370, 179), (3383, 179), (3415, 179), (3453, 179), (3501, 179), (3524, 179), (3555, 179), (3593, 179), (1165, 179), (3722, 179), (3736, 179), (3814, 179), (3823, 179), (3843, 179), (3958, 179), (4025, 179), (2258, 179), (2376, 179), (2432, 179), (2555, 179), (3144, 179), (3197, 179), (3382, 179), (3396, 179), (3416, 179), (3447, 179), (3460, 179), (3477, 179), (3494, 179), (3563, 179), (3587, 179), (3685, 179), (3692, 179), (3697, 179), (3751, 179), (3752, 179), (3757, 179), (3765, 179), (3862, 179), (3887, 179), (3892, 179), (3943, 179), (3977, 179), (4004, 179), (4056, 179), (3145, 179), (3183, 179), (3492, 179), (3549, 179), (1041, 179), (3158, 179), (2104, 180), (2185, 180), (2217, 180), (2374, 180), (2457, 180), (2465, 180), (2470, 180), (2561, 180), (1575, 180), (1583, 180), (1941, 180), (1942, 180), (3108, 180), (3127, 180), (3150, 180), (3164, 180), (3198, 180), (3212, 180), (3288, 180), (3289, 180), (3299, 180), (3351, 180), (3365, 180), (3371, 180), (3454, 180), (3458, 180), (3461, 180), (3466, 180), (3504, 180), (3505, 180), (3598, 180), (1237, 180), (3608, 180), (3615, 180), (3668, 180), (3674, 180), (3716, 180), (3729, 180), (3811, 180), (3832, 180), (3861, 180), (3885, 180), (3945, 180), (3993, 180), (4000, 180), (4007, 180), (4020, 180), (4041, 180), (2214, 180), (2224, 180), (2255, 180), (2303, 180), (2584, 180), (3147, 180), (3177, 180), (3217, 180), (3228, 180), (3265, 180), (3394, 180), (3402, 180), (3429, 180), (3434, 180), (3532, 180), (3588, 180), (3597, 180), (3627, 180), (3678, 180), (3695, 180), (3790, 180), (3822, 180), (3836, 180), (3840, 180), (3876, 180), (3987, 180), (4011, 180), (4013, 180), (4021, 180), (4026, 180), (3345, 180), (563, 180), (1248, 180), (869, 181), (2113, 181), (2279, 181), (2291, 181), (2420, 181), (2473, 181), (2511, 181), (2538, 181), (3117, 181), (3123, 181), (3124, 181), (3133, 181), (3152, 181), (3169, 181), (3209, 181), (3213, 181), (3248, 181), (3280, 181), (3283, 181), (3342, 181), (3390, 181), (3401, 181), (3411, 181), (3439, 181), (3479, 181), (3508, 181), (3522, 181), (3581, 181), (3589, 181), (3605, 181), (3609, 181), (3733, 181), (3824, 181), (3890, 181), (3914, 181), (3939, 181), (3963, 181), (4067, 181), (2178, 181), (3143, 181), (3193, 181), (3290, 181), (3354, 181), (3355, 181), (3375, 181), (3386, 181), (3578, 181), (3585, 181), (3684, 181), (3828, 181), (4002, 181), (4005, 181), (4018, 181), (4081, 181), (3503, 181), (2122, 182), (2226, 182), (2268, 182), (2402, 182), (2414, 182), (2532, 182), (2591, 182), (3196, 182), (3230, 182), (3252, 182), (3275, 182), (3305, 182), (3321, 182), (3322, 182), (3327, 182), (3427, 182), (3430, 182), (3437, 182), (3459, 182), (3473, 182), (3518, 182), (3520, 182), (3552, 182), (1085, 182), (1288, 182), (1309, 182), (3611, 182), (3621, 182), (3639, 182), (3649, 182), (3680, 182), (3686, 182), (3706, 182), (3708, 182), (3771, 182), (3772, 182), (3807, 182), (3834, 182), (3838, 182), (3942, 182), (3954, 182), (3970, 182), (4049, 182), (4075, 182), (2281, 182), (2540, 182), (3103, 182), (3110, 182), (3135, 182), (3210, 182), (3324, 182), (3379, 182), (3391, 182), (3392, 182), (3419, 182), (3444, 182), (3502, 182), (3527, 182), (3576, 182), (3577, 182), (3579, 182), (3667, 182), (3712, 182), (3783, 182), (3848, 182), (3858, 182), (3865, 182), (3906, 182), (2110, 182), (3253, 182), (2477, 183), (2530, 183), (3165, 183), (3194, 183), (3274, 183), (3333, 183), (3356, 183), (3431, 183), (3872, 183), (3873, 183), (4047, 183), (3162, 183), (3276, 183), (3304, 183), (3337, 183), (3395, 183), (3583, 183), (3960, 183), (881, 183), (3449, 183), (3249, 184), (3421, 184), (3456, 184), (1319, 184), (3420, 184), (148, 185), (3118, 185), (2406, 186), (1307, 186), (1308, 186), (1316, 186), (1460, 186), (3493, 186), (3495, 186), (883, 187), (1416, 187), (1103, 188), (1159, 189), (1106, 190), (1421, 191), (1002, 193), (1429, 194), (941, 195), (1368, 195), (1193, 197), (1040, 199), (1200, 201), (1489, 201), (1399, 202), (1066, 202), (1479, 204), (1026, 204), (464, 205), (3918, 205), (1252, 205), (655, 205), (830, 206), (1192, 206), (1353, 206), (1464, 206), (1189, 207), (1286, 208), (1398, 208), (1468, 208), (1133, 209), (1081, 209), (794, 209), (1418, 210), (1161, 211), (1185, 212), (1320, 212), (1331, 212), (209, 212), (1258, 213), (1306, 213), (1396, 213), (1136, 214), (746, 214), (378, 215), (1072, 215), (1117, 215), (1184, 215), (677, 216), (1475, 216), (1467, 216), (729, 217), (1003, 217), (1488, 217), (1229, 218), (1300, 218), (1426, 218), (52, 218), (1094, 219), (1337, 219), (760, 220), (1025, 220), (1188, 220), (1371, 220), (817, 220), (1459, 221), (433, 221), (1367, 222), (1045, 222), (1010, 224), (1452, 224), (152, 225), (942, 225), (425, 226), (1061, 227), (1296, 227), (832, 227), (833, 227), (851, 227), (1162, 227), (169, 228), (963, 229), (1461, 229), (354, 229), (1090, 229), (474, 230), (1073, 230), (1207, 230), (1158, 231), (1160, 231), (1201, 231), (1260, 231), (1101, 232), (1138, 232), (455, 232), (1265, 232), (1250, 232), (757, 233), (447, 233), (1379, 233), (1436, 233), (504, 234), (691, 234), (1256, 234), (1498, 234), (592, 235), (476, 235), (1343, 235), (1012, 236), (1317, 236), (1423, 236), (1463, 236), (1121, 237), (1150, 237), (1407, 237), (979, 238), (1023, 238), (1152, 238), (1284, 238), (1077, 238), (960, 239), (1164, 239), (1173, 239), (578, 240), (847, 240), (1174, 240), (1365, 240), (608, 241), (182, 241), (1496, 241), (1401, 241), (1142, 241), (142, 242), (1149, 242), (1139, 242), (505, 243), (692, 243), (1070, 243), (1098, 243), (1383, 243), (1390, 243), (619, 243), (670, 244), (1344, 244), (983, 244), (924, 245), (322, 245), (1274, 245), (776, 245), (1107, 245), (555, 246), (1178, 246), (1451, 246), (1454, 246), (542, 246), (755, 246), (1195, 246), (509, 246), (998, 247), (29, 247), (664, 247), (875, 247), (1145, 247), (1148, 247), (1370, 248), (1373, 248), (1068, 248), (1114, 248), (732, 248), (976, 249), (250, 249), (1194, 249), (1321, 249), (270, 249), (600, 250), (396, 250), (1049, 250), (1210, 250), (1082, 251), (1144, 251), (599, 251), (1212, 251), (598, 252), (411, 252), (810, 253), (897, 253), (994, 253), (1227, 253), (1291, 253), (67, 253), (1224, 254), (1017, 255), (1295, 255), (1334, 255), (891, 255), (1147, 255), (714, 256), (200, 256), (386, 256), (1267, 256), (1447, 256), (882, 256), (539, 257), (1349, 257), (1474, 257), (624, 258), (1123, 258), (1197, 258), (1355, 258), (1487, 258), (688, 258), (84, 258), (195, 258), (1079, 258), (1059, 258), (459, 259), (1486, 259), (449, 259), (715, 260), (964, 260), (324, 260), (450, 260), (1290, 260), (457, 261), (1236, 261), (1336, 261), (1440, 261), (79, 261), (394, 261), (748, 262), (1387, 262), (1438, 262), (1019, 262), (528, 263), (1009, 263), (1119, 263), (1264, 263), (1406, 263), (779, 263), (419, 263), (657, 264), (462, 264), (1283, 264), (177, 264), (517, 265), (908, 265), (953, 265), (1239, 265), (1469, 265), (1220, 266), (1328, 266), (1332, 266), (1356, 266), (1414, 266), (1381, 266), (551, 267), (906, 267), (1122, 267), (1190, 267), (1268, 268), (1403, 268), (1465, 268), (920, 268), (1292, 268), (1230, 268), (540, 268), (532, 269), (689, 269), (636, 269), (855, 270), (1033, 270), (1262, 270), (1310, 270), (1324, 270), (1359, 270), (1408, 270), (1434, 270), (909, 270), (685, 270), (1441, 271), (895, 271), (375, 271), (1279, 271), (475, 271), (134, 272), (1076, 272), (1218, 272), (669, 273), (684, 273), (1156, 273), (1374, 273), (1490, 273), (1351, 273), (1364, 273), (334, 274), (1213, 274), (1022, 274), (1405, 274), (787, 274), (758, 275), (1151, 275), (1333, 275), (1340, 275), (423, 275), (529, 276), (856, 276), (861, 276), (985, 276), (1021, 276), (1055, 276), (1186, 276), (800, 277), (1064, 277), (1099, 277), (1259, 277), (610, 277), (1293, 277), (702, 278), (788, 278), (824, 278), (32, 278), (1303, 278), (1199, 279), (1315, 279), (651, 279), (907, 279), (1339, 280), (1430, 280), (1446, 280), (647, 280), (1477, 280), (627, 281), (780, 281), (400, 281), (1330, 281), (1361, 281), (154, 281), (1054, 281), (927, 282), (391, 282), (1141, 282), (1378, 282), (719, 282), (223, 282), (353, 283), (1242, 283), (1243, 283), (1431, 283), (1471, 283), (796, 283), (836, 284), (30, 284), (365, 284), (1084, 284), (546, 284), (531, 285), (754, 285), (799, 285), (1108, 285), (1157, 285), (581, 285), (823, 286), (1362, 286), (987, 286), (232, 286), (742, 287), (1087, 287), (1285, 287), (553, 288), (954, 288), (371, 288), (497, 288), (1130, 288), (1313, 288), (511, 288), (720, 288), (1352, 289), (1380, 289), (905, 289), (974, 290), (126, 290), (336, 290), (1013, 290), (1129, 290), (1411, 290), (798, 290), (438, 290), (1080, 290), (773, 291), (802, 291), (950, 291), (1305, 291), (564, 291), (1335, 291), (870, 292), (880, 292), (884, 292), (21, 292), (138, 292), (422, 292), (1417, 292), (1052, 292), (1057, 292), (584, 293), (333, 293), (1053, 293), (1065, 293), (1437, 293), (1177, 293), (524, 294), (645, 294), (682, 294), (248, 294), (1375, 294), (74, 294), (1075, 294), (231, 294), (637, 295), (958, 295), (406, 295), (499, 295), (1134, 295), (1167, 295), (1187, 295), (1222, 295), (1409, 295), (480, 295), (1484, 295), (569, 296), (109, 296), (1097, 296), (1466, 296), (236, 296), (566, 297), (646, 297), (726, 297), (844, 297), (936, 297), (1050, 297), (1115, 297), (1318, 297), (1493, 297), (649, 298), (388, 298), (1311, 298), (1249, 298), (916, 298), (516, 299), (1034, 299), (1095, 299), (1172, 299), (654, 300), (749, 300), (781, 300), (1030, 300), (1032, 300), (1175, 300), (1275, 300), (1376, 300), (71, 300), (1203, 300), (601, 301), (948, 301), (114, 301), (120, 301), (131, 301), (176, 301), (206, 301), (1253, 301), (1314, 301), (1462, 301), (3951, 301), (421, 301), (122, 301), (1289, 301), (703, 301), (656, 302), (694, 302), (801, 302), (845, 302), (962, 302), (467, 302), (975, 302), (435, 302), (1027, 302), (1135, 302), (1304, 302), (1363, 303), (1491, 303), (556, 303), (228, 303), (1069, 303), (1126, 303), (1478, 303), (589, 303), (60, 303), (614, 304), (93, 304), (283, 304), (398, 304), (1217, 304), (946, 304), (537, 305), (678, 305), (771, 305), (803, 305), (129, 305), (904, 305), (116, 306), (288, 306), (331, 306), (448, 306), (1093, 306), (1127, 306), (1219, 306), (820, 306), (272, 306), (244, 306), (215, 306), (1078, 306), (590, 307), (1020, 307), (1456, 307), (846, 307), (1453, 307), (82, 307), (575, 308), (922, 308), (1183, 308), (1223, 308), (1272, 308), (1457, 308), (12, 308), (1342, 308), (1415, 308), (807, 308), (1015, 309), (1206, 309), (1240, 309), (299, 309), (1214, 309), (235, 310), (427, 310), (538, 310), (125, 310), (432, 310), (166, 310), (659, 311), (146, 311), (491, 311), (1171, 311), (1263, 311), (238, 311), (1043, 311), (149, 312), (1058, 312), (1402, 312), (662, 312), (16, 312), (237, 312), (784, 313), (50, 313), (1028, 313), (1029, 313), (1278, 313), (1298, 313), (1287, 313), (767, 314), (1254, 314), (791, 314), (949, 314), (86, 314), (1273, 314), (311, 314), (768, 314), (387, 314), (926, 315), (4, 315), (412, 315), (1168, 315), (1181, 315), (674, 315), (1492, 315), (424, 315), (716, 316), (899, 316), (75, 316), (106, 316), (1326, 316), (1439, 316), (151, 316), (162, 316), (523, 316), (593, 317), (623, 317), (744, 317), (813, 317), (826, 317), (965, 317), (25, 317), (105, 317), (434, 317), (1433, 317), (1096, 317), (527, 318), (640, 318), (918, 318), (1109, 318), (1166, 318), (1216, 318), (1246, 318), (1270, 318), (1395, 318), (193, 318), (407, 318), (741, 319), (821, 319), (1060, 319), (1062, 319), (1366, 319), (1428, 319), (567, 320), (638, 320), (786, 320), (268, 320), (440, 320), (490, 320), (1051, 320), (1257, 320), (83, 320), (319, 320), (966, 321), (198, 321), (1038, 321), (1325, 321), (1327, 321), (1067, 321), (1424, 321), (349, 321), (369, 321), (611, 322), (1483, 322), (658, 322), (683, 323), (738, 323), (939, 323), (80, 323), (217, 323), (249, 323), (1104, 323), (486, 323), (617, 324), (212, 324), (1042, 324), (1048, 324), (1198, 324), (1449, 324), (816, 324), (885, 324), (968, 324), (87, 324), (308, 324), (1137, 324), (675, 324), (759, 325), (866, 325), (1176, 325), (603, 325), (216, 325), (364, 325), (536, 325), (591, 326), (352, 326), (1004, 326), (1118, 326), (1131, 326), (1357, 326), (1385, 326), (53, 326), (184, 326), (1235, 326), (520, 327), (629, 327), (921, 327), (45, 327), (220, 327), (323, 327), (372, 327), (850, 328), (872, 328), (947, 328), (487, 328), (1071, 328), (1480, 328), (667, 328), (225, 328), (1360, 328), (923, 329), (990, 329), (179, 329), (410, 329), (1397, 329), (175, 329), (1039, 329), (552, 329), (13, 329), (612, 330), (626, 330), (42, 330), (43, 330), (233, 330), (535, 330), (580, 330), (88, 330), (1208, 330), (545, 331), (594, 331), (739, 331), (808, 331), (828, 331), (835, 331), (471, 331), (1294, 331), (915, 331), (339, 331), (1226, 331), (1458, 331), (73, 332), (128, 332), (205, 332), (277, 332), (313, 332), (1455, 332), (971, 332), (727, 333), (889, 333), (186, 333), (1231, 333), (639, 333), (145, 333), (340, 333), (510, 334), (632, 334), (710, 334), (913, 334), (980, 334), (1312, 334), (1422, 334), (957, 334), (22, 334), (718, 335), (871, 335), (995, 335), (309, 335), (1113, 335), (1266, 335), (1497, 335), (696, 335), (565, 336), (650, 336), (652, 336), (711, 336), (859, 336), (1323, 336), (1354, 336), (595, 336), (33, 337), (291, 337), (408, 337), (234, 337), (500, 338), (809, 338), (819, 338), (986, 338), (992, 338), (300, 338), (350, 338), (397, 338), (1281, 338), (1443, 338), (273, 338), (1470, 338), (981, 338), (282, 339), (1196, 339), (1444, 339), (797, 339), (81, 340), (722, 340), (753, 340), (1007, 340), (663, 341), (705, 341), (707, 341), (173, 341), (418, 341), (452, 341), (483, 341), (498, 341), (512, 341), (634, 341), (970, 342), (201, 342), (202, 342), (1413, 342), (704, 342), (76, 342), (609, 343), (731, 343), (853, 343), (978, 343), (44, 343), (56, 343), (1000, 343), (1125, 343), (1155, 343), (1372, 343), (1427, 343), (1485, 343), (935, 343), (558, 344), (607, 344), (849, 344), (864, 344), (153, 344), (293, 344), (380, 344), (414, 344), (561, 344), (930, 344), (1191, 344), (1044, 344), (653, 345), (988, 345), (997, 345), (221, 345), (341, 345), (405, 345), (1205, 345), (357, 345), (507, 346), (549, 346), (721, 346), (789, 346), (822, 346), (984, 346), (189, 346), (230, 346), (366, 346), (1394, 346), (829, 346), (140, 346), (417, 346), (1046, 346), (1169, 346), (58, 346), (222, 346), (724, 347), (769, 347), (100, 347), (306, 347), (429, 347), (1400, 347), (1445, 347), (782, 347), (38, 347), (1341, 347), (543, 348), (132, 348), (194, 348), (214, 348), (269, 348), (285, 348), (478, 348), (1116, 348), (1345, 348), (586, 348), (526, 349), (160, 349), (1338, 349), (606, 350), (709, 350), (932, 350), (940, 350), (956, 350), (982, 350), (139, 350), (430, 350), (1182, 350), (1412, 350), (890, 350), (178, 350), (602, 351), (661, 351), (668, 351), (735, 351), (762, 351), (959, 351), (999, 351), (1350, 351), (1481, 351), (533, 351), (910, 351), (5, 351), (470, 351), (671, 352), (712, 352), (728, 352), (917, 352), (229, 352), (325, 352), (1329, 352), (1435, 352), (993, 352), (1035, 352), (1245, 352), (1450, 352), (620, 352), (68, 352), (666, 353), (676, 353), (136, 353), (210, 353), (259, 353), (420, 353), (1083, 353), (929, 353), (274, 353), (585, 354), (587, 354), (628, 354), (852, 354), (972, 354), (147, 354), (204, 354), (1074, 354), (573, 354), (101, 354), (111, 354), (290, 354), (133, 354), (672, 355), (736, 355), (955, 355), (1255, 355), (64, 355), (97, 355), (393, 355), (818, 355), (842, 355), (61, 356), (103, 356), (276, 356), (358, 356), (1420, 356), (1494, 356), (793, 357), (805, 357), (912, 357), (167, 357), (239, 357), (1132, 357), (548, 358), (568, 358), (945, 358), (41, 358), (496, 358), (1001, 358), (541, 359), (778, 359), (934, 359), (226, 359), (437, 359), (484, 359), (1392, 359), (713, 359), (307, 359), (348, 359), (1153, 359), (513, 360), (576, 360), (681, 360), (766, 360), (893, 360), (192, 360), (381, 360), (1225, 360), (571, 360), (734, 360), (390, 360), (508, 361), (733, 361), (59, 361), (150, 361), (1088, 361), (368, 361), (482, 361), (191, 362), (329, 362), (1180, 362), (1482, 362), (642, 362), (973, 362), (862, 363), (892, 363), (901, 363), (26, 363), (413, 363), (1442, 363), (1448, 363), (1473, 363), (522, 363), (506, 364), (514, 364), (583, 364), (621, 364), (275, 364), (1008, 364), (1024, 364), (1031, 364), (952, 364), (165, 364), (643, 365), (725, 365), (763, 365), (1014, 365), (343, 365), (479, 365), (557, 366), (572, 366), (577, 366), (811, 366), (858, 366), (903, 366), (91, 366), (98, 366), (1047, 366), (1089, 366), (503, 367), (695, 367), (770, 367), (888, 367), (933, 367), (227, 367), (251, 367), (367, 367), (625, 367), (761, 367), (630, 368), (730, 368), (78, 368), (89, 368), (123, 368), (124, 368), (286, 368), (342, 368), (570, 368), (383, 368), (463, 368), (550, 369), (898, 369), (85, 369), (135, 369), (168, 369), (218, 369), (356, 369), (436, 369), (1111, 369), (544, 370), (775, 370), (15, 370), (389, 370), (977, 370), (697, 371), (944, 371), (20, 371), (121, 371), (144, 371), (1425, 371), (525, 372), (900, 372), (157, 372), (442, 372), (1215, 372), (700, 372), (747, 372), (180, 373), (257, 373), (456, 373), (1143, 373), (39, 373), (1170, 373), (55, 373), (1238, 373), (774, 374), (777, 374), (854, 374), (878, 374), (24, 374), (304, 374), (338, 374), (370, 374), (376, 374), (615, 375), (7, 375), (40, 375), (117, 375), (264, 375), (266, 375), (298, 375), (377, 375), (382, 375), (1063, 375), (1382, 375), (886, 375), (868, 376), (351, 376), (439, 376), (489, 376), (1124, 376), (1393, 376), (34, 376), (404, 376), (1086, 376), (501, 377), (648, 377), (9, 377), (19, 377), (113, 377), (130, 377), (262, 377), (867, 377), (515, 378), (588, 378), (756, 378), (764, 378), (265, 378), (1211, 378), (873, 378), (14, 378), (618, 379), (693, 379), (737, 379), (806, 379), (812, 379), (838, 379), (65, 379), (253, 379), (279, 379), (314, 379), (316, 379), (492, 379), (69, 379), (6, 380), (385, 380), (72, 380), (104, 380), (1276, 380), (326, 380), (708, 381), (814, 381), (260, 381), (441, 381), (92, 382), (295, 382), (301, 382), (310, 382), (485, 382), (493, 382), (0, 382), (280, 382), (362, 382), (1204, 382), (605, 383), (831, 383), (18, 383), (373, 383), (374, 383), (460, 383), (574, 383), (911, 383), (384, 383), (686, 384), (36, 384), (318, 384), (415, 384), (827, 384), (1244, 384), (521, 385), (604, 385), (723, 385), (305, 385), (297, 385), (488, 385), (894, 386), (355, 386), (1241, 386), (1472, 386), (469, 386), (680, 387), (772, 387), (792, 387), (127, 387), (174, 387), (245, 387), (1247, 387), (1251, 387), (783, 387), (321, 387), (967, 387), (156, 388), (181, 388), (454, 388), (57, 388), (183, 388), (928, 388), (560, 389), (631, 389), (841, 389), (879, 389), (170, 389), (240, 389), (345, 389), (1112, 389), (665, 390), (62, 390), (158, 390), (141, 390), (402, 390), (839, 391), (107, 391), (207, 391), (477, 391), (717, 391), (887, 391), (687, 392), (701, 392), (751, 392), (902, 392), (267, 392), (332, 392), (392, 392), (399, 392), (453, 392), (865, 392), (502, 393), (554, 393), (596, 393), (919, 393), (943, 393), (49, 393), (271, 393), (519, 394), (877, 394), (171, 394), (185, 394), (258, 394), (263, 394), (303, 394), (1391, 394), (635, 395), (840, 395), (951, 395), (47, 395), (137, 395), (241, 395), (446, 395), (795, 395), (143, 395), (1233, 395), (1282, 395), (641, 396), (860, 396), (931, 396), (51, 396), (112, 396), (159, 396), (224, 396), (660, 396), (834, 397), (876, 397), (991, 397), (278, 397), (3, 397), (403, 397), (296, 397), (938, 398), (989, 398), (597, 398), (673, 399), (750, 399), (96, 399), (302, 399), (458, 399), (1277, 399), (28, 399), (765, 400), (359, 400), (1120, 400), (745, 400), (699, 401), (188, 401), (196, 401), (466, 401), (287, 401), (896, 402), (961, 402), (243, 402), (431, 402), (461, 402), (914, 402), (445, 402), (518, 403), (706, 403), (95, 403), (219, 403), (252, 403), (616, 403), (37, 403), (327, 403), (90, 403), (163, 404), (409, 404), (2, 404), (242, 404), (284, 405), (468, 405), (481, 405), (559, 406), (874, 406), (444, 406), (562, 407), (690, 407), (752, 407), (815, 407), (31, 407), (401, 407), (530, 408), (804, 408), (211, 408), (118, 408), (77, 409), (622, 410), (94, 410), (328, 411), (172, 411), (1091, 411), (347, 412), (494, 412), (472, 412), (534, 413), (208, 413), (633, 413), (925, 413), (1, 413), (63, 413), (108, 414), (187, 414), (843, 414), (473, 414), (547, 415), (679, 415), (698, 415), (361, 415), (161, 415), (613, 416), (35, 416), (102, 416), (197, 416), (312, 416), (330, 417), (443, 417), (8, 418), (255, 418), (379, 418), (23, 418), (996, 419), (451, 419), (495, 419), (317, 420), (360, 420), (465, 420), (115, 421), (863, 422), (256, 422), (395, 422), (1369, 422), (99, 423), (246, 423), (17, 424), (281, 424), (11, 425), (315, 425), (743, 425), (110, 426), (320, 426), (203, 426), (335, 427), (344, 427), (54, 428), (66, 428), (190, 428), (254, 429), (46, 430), (164, 430), (70, 433), (199, 433), (337, 435), (1301, 435), (644, 436), (10, 436), (119, 437), (155, 442), (292, 442), (27, 446), (289, 464), (261, 583)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W4kXeKaJRc9Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "testW = []\n",
        "countImgs = 0  # No of images in test set\n",
        "while countImgs<len(InfoDisk)*0.1:\n",
        "  testW.append(writers[-1])\n",
        "  countImgs += writers[-1][1]\n",
        "  writers = writers[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tr6PvmmWRemd",
        "colab_type": "code",
        "outputId": "737c2f73-0cea-471e-b189-2410c4a7e245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "print(testW)\n",
        "len(testW)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(261, 583), (289, 464), (27, 446), (292, 442), (155, 442), (119, 437), (10, 436), (644, 436), (1301, 435), (337, 435), (199, 433), (70, 433), (164, 430), (46, 430), (254, 429), (190, 428), (66, 428), (54, 428), (344, 427), (335, 427), (203, 426), (320, 426), (110, 426), (743, 425), (315, 425), (11, 425), (281, 424), (17, 424), (246, 423), (99, 423), (1369, 422), (395, 422), (256, 422), (863, 422), (115, 421), (465, 420), (360, 420), (317, 420), (495, 419), (451, 419), (996, 419), (23, 418), (379, 418), (255, 418), (8, 418), (443, 417), (330, 417), (312, 416), (197, 416), (102, 416), (35, 416), (613, 416), (161, 415), (361, 415), (698, 415), (679, 415), (547, 415), (473, 414), (843, 414), (187, 414), (108, 414), (63, 413), (1, 413), (925, 413), (633, 413), (208, 413), (534, 413), (472, 412), (494, 412), (347, 412), (1091, 411), (172, 411), (328, 411), (94, 410), (622, 410), (77, 409), (118, 408), (211, 408), (804, 408), (530, 408), (401, 407), (31, 407), (815, 407), (752, 407), (690, 407), (562, 407), (444, 406), (874, 406), (559, 406), (481, 405), (468, 405), (284, 405), (242, 404), (2, 404), (409, 404), (163, 404), (90, 403), (327, 403), (37, 403), (616, 403), (252, 403), (219, 403), (95, 403), (706, 403), (518, 403), (445, 402), (914, 402), (461, 402), (431, 402), (243, 402), (961, 402), (896, 402), (287, 401), (466, 401), (196, 401), (188, 401), (699, 401), (745, 400), (1120, 400), (359, 400), (765, 400), (28, 399), (1277, 399), (458, 399), (302, 399), (96, 399), (750, 399), (673, 399), (597, 398), (989, 398), (938, 398), (296, 397), (403, 397), (3, 397), (278, 397), (991, 397), (876, 397), (834, 397), (660, 396), (224, 396), (159, 396), (112, 396), (51, 396), (931, 396), (860, 396), (641, 396), (1282, 395), (1233, 395), (143, 395), (795, 395), (446, 395), (241, 395), (137, 395), (47, 395), (951, 395), (840, 395), (635, 395), (1391, 394), (303, 394), (263, 394), (258, 394), (185, 394), (171, 394), (877, 394), (519, 394), (271, 393), (49, 393), (943, 393), (919, 393), (596, 393), (554, 393), (502, 393), (865, 392), (453, 392), (399, 392), (392, 392), (332, 392), (267, 392), (902, 392), (751, 392), (701, 392), (687, 392), (887, 391), (717, 391), (477, 391), (207, 391), (107, 391), (839, 391), (402, 390), (141, 390), (158, 390), (62, 390), (665, 390), (1112, 389), (345, 389), (240, 389), (170, 389), (879, 389), (841, 389), (631, 389)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "t3e33zRkRhDU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split and stratify\n",
        "# 80% : 10% : 10%\n",
        "# shuffle(writers)\n",
        "trainW = []\n",
        "validationW = []\n",
        "\n",
        "for i in range(0, len(writers)):\n",
        "  if i%10==9:\n",
        "    validationW.append(writers[i])\n",
        "  else:\n",
        "    trainW.append(writers[i])\n",
        "\n",
        "trainW = set(trainW)\n",
        "validationW = set(validationW)\n",
        "testW = set(testW)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6iTnKCIuRiq-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "testW = [x[0] for x in testW]\n",
        "validationW = [x[0] for x in validationW]\n",
        "trainW = [x[0] for x in trainW]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EloLiBHqRkBz",
        "colab_type": "code",
        "outputId": "4cc723c4-fda0-47d0-c6df-cc3821f24ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(trainW))\n",
        "print(len(validationW))\n",
        "print(len(testW))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3057\n",
            "339\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_8-By7vaRlDu",
        "colab_type": "code",
        "outputId": "ed318349-d8a8-43c2-e9f2-460ee147a2d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_Images = []\n",
        "train_Labels = []\n",
        "train_Writers = []\n",
        "\n",
        "validation_Images = []\n",
        "validation_Labels = []\n",
        "validation_Writers = []\n",
        "\n",
        "test_Images = []\n",
        "test_Labels = []\n",
        "test_Writers = []\n",
        "\n",
        "shuffle(InfoDisk)  # for randomization of labels; writers are fitted anywhay\n",
        "for path, label, writer in InfoDisk:\n",
        "  writer = int(writer)\n",
        "  img = mpimg.imread(os.path.join('./ImageDisk', path))\n",
        "  if writer in testW:\n",
        "    test_Images.append(img.reshape(28, 28, 1)/255.0)\n",
        "    test_Labels.append(OH_L.encode(label))\n",
        "    test_Writers.append(writer)\n",
        "  elif writer in validationW:\n",
        "    validation_Images.append(img.reshape(28, 28, 1)/255.0)\n",
        "    validation_Labels.append(OH_L.encode(label))\n",
        "    validation_Writers.append(writer)\n",
        "  elif writer in trainW:\n",
        "    train_Images.append(img.reshape(28, 28, 1)/255.0)\n",
        "    train_Labels.append(OH_L.encode(label))\n",
        "    train_Writers.append(writer)\n",
        "  else:\n",
        "    print('Unrecognized writer, ', writer)  # Throw exception"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 6s, sys: 35.8 s, total: 2min 42s\n",
            "Wall time: 5min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cdb9evjrRmwZ",
        "colab_type": "code",
        "outputId": "f148028a-41ad-4ec4-8127-1697104d347b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(train_Writers))\n",
        "print(len(validation_Writers))\n",
        "print(len(test_Writers))\n",
        "print()\n",
        "print(len(train_Labels))\n",
        "print(len(validation_Labels))\n",
        "print(len(test_Labels))\n",
        "print()\n",
        "print(len(train_Images))\n",
        "print(len(validation_Images))\n",
        "print(len(test_Images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "659541\n",
            "73209\n",
            "81505\n",
            "\n",
            "659541\n",
            "73209\n",
            "81505\n",
            "\n",
            "659541\n",
            "73209\n",
            "81505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6an07VYtRtH3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ]
    },
    {
      "metadata": {
        "id": "7DRCY2OuRsVN",
        "colab_type": "code",
        "outputId": "2961fb66-186d-4047-ab1f-f548d1946598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "\n",
        "recognizer = load_model('./drive/My Drive/New_Approach_29.12.2018/baseline_model.h5')\n",
        "finder = Model(inputs=recognizer.input, outputs=recognizer.get_layer('next_to_last').output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CzB0Y2YNSUer",
        "colab_type": "code",
        "outputId": "2cf057d1-cf36-4ebf-9ed1-0d779882b66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "recognizer.evaluate(x=np.array(train_Images), y=np.array(train_Labels), batch_size=256, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "659541/659541 [==============================] - 28s 42us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29930853555806036, 0.8836448378503469]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "u8eaE5vsSRDg",
        "colab_type": "code",
        "outputId": "f9c3526f-2749-40f5-9d48-50db8a03cf5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "recognizer.evaluate(x=np.array(validation_Images), y=np.array(validation_Labels), batch_size=256, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73209/73209 [==============================] - 5s 70us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32758882487221935, 0.8739362647597281]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "XHPuqFjBSQi9",
        "colab_type": "code",
        "outputId": "69833fc5-c1d6-4542-ae7e-e7d5b7bcccb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "recognizer.evaluate(x=np.array(test_Images), y=np.array(test_Labels), batch_size=256, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81505/81505 [==============================] - 6s 79us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3596773234578512, 0.8735046929563088]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "WyW5UDK3SVme",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Best Model: Clustering by labels + KNN+"
      ]
    },
    {
      "metadata": {
        "id": "ljH61hbqTJay",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Clustering by instances"
      ]
    },
    {
      "metadata": {
        "id": "vup7cgNvSZi8",
        "colab_type": "code",
        "outputId": "825876de-2113-4d29-b227-f2334cef6713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "labels = sorted([int(l) for l in labels])  # int\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i1EYFhgeSfXC",
        "colab_type": "code",
        "outputId": "0a2b4ef9-cf78-45f9-bb0f-c3721aad3af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "IVectors = {}  # Ascii code is key, 48, 49, 50, ...\n",
        "for l in labels:\n",
        "  IVectors[l] = []\n",
        "print(IVectors)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{48: [], 49: [], 50: [], 51: [], 52: [], 53: [], 54: [], 55: [], 56: [], 57: [], 65: [], 66: [], 67: [], 68: [], 69: [], 70: [], 71: [], 72: [], 73: [], 74: [], 75: [], 76: [], 77: [], 78: [], 79: [], 80: [], 81: [], 82: [], 83: [], 84: [], 85: [], 86: [], 87: [], 88: [], 89: [], 90: [], 97: [], 98: [], 99: [], 100: [], 101: [], 102: [], 103: [], 104: [], 105: [], 106: [], 107: [], 108: [], 109: [], 110: [], 111: [], 112: [], 113: [], 114: [], 115: [], 116: [], 117: [], 118: [], 119: [], 120: [], 121: [], 122: []}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "akKt7-0DSh1U",
        "colab_type": "code",
        "outputId": "88d98fdd-f58f-409d-a2cd-75140bf11906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for k in range(0, len(validation_Images)):\n",
        "  l = int(OH_L.decode(validation_Labels[k]))\n",
        "  next_to_last = finder.predict(np.array([validation_Images[k]]))[0]\n",
        "  IVectors[l].append(next_to_last)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 14s, sys: 15.5 s, total: 3min 29s\n",
            "Wall time: 2min 28s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wLgMY83OShuM",
        "colab_type": "code",
        "outputId": "28aa21dd-0fae-41bd-a4f4-56117040266d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for k in range(0, len(train_Images)):\n",
        "  l = int(OH_L.decode(train_Labels[k]))\n",
        "  next_to_last = finder.predict(np.array([train_Images[k]]))[0]\n",
        "  IVectors[l].append(next_to_last)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 29min 23s, sys: 2min 10s, total: 31min 33s\n",
            "Wall time: 22min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qWMLSnCTShoe",
        "colab_type": "code",
        "outputId": "1d497773-1f93-4541-a56a-7d654817163a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "S = 0\n",
        "for l in IVectors.keys():\n",
        "  S += len(IVectors[l])\n",
        "print(S)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "732750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "63I_YPPnShiy",
        "colab_type": "code",
        "outputId": "f84a7937-3bf5-431f-8370-030ebdd83fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(validation_Images))\n",
        "print(len(train_Images))\n",
        "print(len(validation_Images)+len(train_Images))\n",
        "\n",
        "print(labels)\n",
        "print(len(labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73209\n",
            "659541\n",
            "732750\n",
            "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122]\n",
            "62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5c9D3EijShc4",
        "colab_type": "code",
        "outputId": "fb447b91-993c-4bae-f2d7-03875712cbcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print([len(IVectors[l]) for l in labels])  # broj slika po svakoj labeli"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[37928, 42193, 37689, 38659, 36787, 34383, 37547, 39455, 37189, 37196, 6719, 4108, 10154, 4779, 5041, 8949, 2783, 3339, 11891, 3967, 2667, 5269, 8963, 8473, 24266, 8408, 2844, 5155, 20171, 9791, 12428, 4872, 4948, 3016, 4839, 2982, 9597, 5310, 3100, 10033, 22948, 2787, 3786, 8541, 2957, 2056, 2770, 14900, 2927, 10948, 3019, 2644, 3128, 13352, 2948, 17183, 3127, 3195, 2980, 3102, 2577, 2987]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zWvKfhRrShXS",
        "colab_type": "code",
        "outputId": "8f330cc1-9870-442f-bc4d-eed86322a3dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "N_clusters = [int(min(30, 1+max(len(IVectors[l])/1000, 4))) for i, l in enumerate(labels)]  # CHANGE THIS!\n",
        "print(N_clusters)\n",
        "print(sum(N_clusters))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 7, 5, 11, 5, 6, 9, 5, 5, 12, 5, 5, 6, 9, 9, 25, 9, 5, 6, 21, 10, 13, 5, 5, 5, 5, 5, 10, 6, 5, 11, 23, 5, 5, 9, 5, 5, 5, 15, 5, 11, 5, 5, 5, 14, 5, 18, 5, 5, 5, 5, 5, 5]\n",
            "715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3piT1T-UShRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "ICentroids = {}  # dictionary with centroids for each label\n",
        "kmeans = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2HHfYw1pShMb",
        "colab_type": "code",
        "outputId": "740ad45e-bf76-46ef-c0bc-7a5c80ef9d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for i, l in enumerate(labels):\n",
        "  if kmeans!=None:\n",
        "    del kmeans\n",
        "  kmeans = KMeans(n_clusters=N_clusters[i], n_init=10, max_iter=300, tol=1e-4, precompute_distances=False, verbose=0)  # 15, 250/10, 300\n",
        "  \n",
        "  kmeans.fit(IVectors[l])\n",
        "  ICentroids[l] = kmeans.cluster_centers_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16min 25s, sys: 2min 8s, total: 18min 33s\n",
            "Wall time: 15min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LMiR2KAiShGN",
        "colab_type": "code",
        "outputId": "ae86c5ba-4e85-4d5c-f494-a92b769ab9ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "ICentroids[48].shape  # Clusters for 'A'; small check"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "-_PEvQJ7Sg_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Normalize clusters; Newly added; Quick fix, small improvements; Normalize together ???\n",
        "for k in ICentroids.keys(): \n",
        "  for j in range(0, ICentroids[k].shape[0]):\n",
        "    ICentroids[k][j] = (ICentroids[k][j] - ICentroids[k][j].mean())/(ICentroids[k][j].std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Qs7G7rYS4sb",
        "colab_type": "code",
        "outputId": "3c0d32b3-18ff-429c-ce06-b76cbe54af56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier  # Estimate the quality of custers\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "Ns = [1,2,3,4,5,7,8,9,10,15]\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for l in labels:\n",
        "  for j in range(0, ICentroids[l].shape[0]):\n",
        "    X_train.append(ICentroids[l][j])\n",
        "    y_train.append(l)\n",
        "\n",
        "for n in Ns:\n",
        "  knn = KNeighborsClassifier(n_neighbors=n, metric='l2')\n",
        "  knn.fit(X_train, y_train)\n",
        "  \n",
        "  score = accuracy_score(knn.predict(finder.predict(np.array(test_Images))), [int(x) for x in OH_L.decode_all(test_Labels)])\n",
        "  print('KNN', n, ': ', score)\n",
        "  del knn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN 1 :  0.8205876940065027\n",
            "KNN 2 :  0.8312250782160604\n",
            "KNN 3 :  0.8213361143488129\n",
            "KNN 4 :  0.8535672658119133\n",
            "KNN 5 :  0.8367584810747807\n",
            "KNN 7 :  0.8458376786700202\n",
            "KNN 8 :  0.8605361634255567\n",
            "KNN 9 :  0.852696153610208\n",
            "KNN 10 :  0.8558370652107232\n",
            "KNN 15 :  0.8153242132384516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-w7e3LgiqEut",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Density class"
      ]
    },
    {
      "metadata": {
        "id": "XGU4edFGrhaz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from  scipy import stats\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9-z2EeaJqELu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# approximating theta parametar - how much I believe in network/knn (initially 0.5)\n",
        "\n",
        "class CharStatistic():\n",
        "  # label\n",
        "  # alpha = 1 (initial)\n",
        "  # beta = 1 (initial)\n",
        "  \n",
        "  def __init__(self, label, alpha=None, beta=None):\n",
        "    self.label = label\n",
        "    \n",
        "    if alpha is not None:\n",
        "      self.alpha = alpha\n",
        "    else:\n",
        "      self.alpha = 1\n",
        "    if beta is not None:\n",
        "      self.beta = beta\n",
        "    else:\n",
        "      self.beta = 1 # hardcoded initial; start with uniform distribution U[0, 1]\n",
        "   \n",
        "  def get_alpha(self):  # getters\n",
        "    return self.alpha\n",
        "  \n",
        "  def get_beta(self):\n",
        "    return self.beta\n",
        "  \n",
        "  def set_alpha(self, alpha):\n",
        "    self.alpha = alpha\n",
        "    \n",
        "  def set_beta(self, beta):\n",
        "    self.beta = beta\n",
        "  \n",
        "  def get_mean(self):\n",
        "    return self.alpha/(self.alpha+self.beta)  # initaially 0.5\n",
        "    # return stats.beta.mean(self.alpha, self.beta)\n",
        "  \n",
        "  def get_standard_deviation(self):\n",
        "    return np.sqrt(self.alpha*self.beta/((self.alpha+self.beta)**2*(self.alpha+self.beta+1)))  # initially 0.1\n",
        "    # return stats.beta.std(self.alpha, self.beta)\n",
        "  \n",
        "  def update_one(self, winnew):  # winnew==1 if knn wins, else its 0\n",
        "    self.alpha += winnew\n",
        "    self.beta += 1 - winnew\n",
        "    \n",
        "  def update_all(self, winnews):  # winnews = [1, 0, 1, ..] 1 if knn wins else 0\n",
        "    N = len(winnews)\n",
        "    z = sum(winnews)\n",
        "    self.alpha += z\n",
        "    self.beta += N - z\n",
        "    \n",
        "  def print_current_density_function(self):  # print current approximation of beta distribution\n",
        "    x = np.linspace(0, 1, 100)\n",
        "    y = stats.beta.pdf(x, self.alpha, self.beta)\n",
        "    plt.xlabel(\"Density approximation for LABEL: \"+self.label)\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.plot(x, y)\n",
        "    plt.fill_between(x, 0, y, color=\"#aaaadd\", alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "  \n",
        "  # FUNCTIONS FOR DECISION MAKING, WHOM TO TRUST:\n",
        "    \n",
        "  def __gt__(self, otherCharStatistic):  # Override operator > on density approximation\n",
        "    if not isinstance(otherCharStatistic, CharStatistic):\n",
        "      raise ValueError(\"Error. Operator overloaded for CharStatistic class\")\n",
        "    if self.get_mean()>otherCharStatistic.get_mean(): # TODO: USE .get_standard_deviation()\n",
        "      return True\n",
        "    else:\n",
        "      return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KNkrNPBJqPt1",
        "colab_type": "code",
        "outputId": "3102b3fb-f070-450b-a7de-287aeaca24a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "S = CharStatistic('A')\n",
        "S1 = CharStatistic('B')\n",
        "S.get_standard_deviation()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28867513459481287"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "Fk2z_YJHu_2i",
        "colab_type": "code",
        "outputId": "a022b564-4181-4078-8b5f-50e3bc0774a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "cell_type": "code",
      "source": [
        "S.print_current_density_function()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGACAYAAAC6OPj9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFLzwZFFGBgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Tt4V-SuZxtgq",
        "colab_type": "code",
        "outputId": "7f9dabc1-f768-41b5-e8d7-2d1f09d67518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "S > S1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "uvLJni45e-M_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# With Stratify, multiple k idea"
      ]
    },
    {
      "metadata": {
        "id": "RKi9XqS_fC2s",
        "colab_type": "code",
        "outputId": "91b20f74-fc36-48c0-9b34-4f9d29afe4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "for char in range(ord('0'), ord('9')+1):\n",
        "  labels.append(chr(char))\n",
        "for char in range(ord('A'), ord('Z')+1):\n",
        "  labels.append(chr(char))\n",
        "for char in range(ord('a'), ord('z')+1):\n",
        "  labels.append(chr(char))\n",
        "print(labels)  \n",
        "print(len(labels))\n",
        "\n",
        "testset = set(test_Writers)\n",
        "print(len(testset))  # No of different writers\n",
        "\n",
        "# TESTDATA[Writer] = [testImagesOfWriter, testLabelsOfWriter]; example: TESTDATA[9] = [testImages9, testLabels9]\n",
        "TESTDATA = {} \n",
        "for writer in testset:\n",
        "  TESTDATA[writer] = [[], []]\n",
        "for i in range(0, len(test_Writers)):\n",
        "    TESTDATA[test_Writers[i]][0].append(test_Images[i])\n",
        "    TESTDATA[test_Writers[i]][1].append(test_Labels[i])\n",
        "\n",
        "def find_minimal(i, vector):  # i is the ascii code: 48.49,...,65,66,...,97,...\n",
        "  # Implicit use of dictionary ICentroids[ASCII]\n",
        "  minindex = 0\n",
        "  mineps = np.linalg.norm(vector-ICentroids[i][0])\n",
        "  for j in range(1, ICentroids[i].shape[0]):  \n",
        "    _mineps = np.linalg.norm(vector-ICentroids[i][j])\n",
        "    if _mineps < mineps:\n",
        "      mineps = _mineps\n",
        "      minindex = j\n",
        "      \n",
        "  return ICentroids[i][minindex].copy()   # CHANGE NUMBER OF CLUSTERS MLADEN IDEA"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "62\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RlDgSkZxfCrv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "winold = 0\n",
        "equal = 0\n",
        "winnew = 0\n",
        "sumS = 0\n",
        "sumS1 = 0\n",
        "sumSboth = 0\n",
        "sumN = 0\n",
        "lenBetterOld = 0\n",
        "lenBetterNew = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rlBndN6mfCgb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "ks = [2, 4, 6, 8, 10]  # outer object for configure get_min_label function and evaluation\n",
        "\n",
        "def get_min_label(history, predicted_vector): # return list of predicted label for k in ks\n",
        "  X_search = []\n",
        "  y_search = []\n",
        "  for (_predicted_label, _original_label) in history.keys():  # Na 90% mreza je rekla _predicted_label a bila je _original_label (imam vector i count)\n",
        "      if _predicted_label == predicted_label:\n",
        "        for _ in range(history[(_predicted_label, _original_label)][1]):\n",
        "          X_search.append(history[(_predicted_label, _original_label)][0])\n",
        "          y_search.append(_original_label)      \n",
        "  \n",
        "  results = {}\n",
        "  for k in ks:\n",
        "    if len(X_search)<k:  # if I cant do knn search with respect to specific k\n",
        "      results[k] = None\n",
        "    else:\n",
        "      knn = KNeighborsClassifier(n_neighbors=k, metric='l2')  # empirically confirm; use heuristic instead of min\n",
        "      knn.fit(X_search, y_search)\n",
        "      results[k] = knn.predict(np.array([predicted_vector]))[0]\n",
        "      \n",
        "  return results # return dict of predictions for each k in ks [1, 2, 4, 6, 8]\n",
        "\n",
        "# Who to believe in prediction\n",
        "# input: (baseline prediction, baseline spectar, knns oredictions, knns spectars)\n",
        "def who_to_believe(predicted_label, writer_network_spectar, min_labels, writer_knn_spectars): # Return optimal k or None if baseline is the best\n",
        "  trust = [writer_network_spectar[chr(predicted_label)].get_mean()]\n",
        "  for k in ks:\n",
        "    if min_labels[k] is None: # no prediction for that k\n",
        "      trust.append(-1)  # baseline is above 0 in any case\n",
        "    else:\n",
        "      trust.append(writer_knn_spectars[k][chr(min_labels[k])].get_mean())  # mean of density approximation for predicted label for specific k \n",
        "    \n",
        "  maxindex = trust.index(max(trust))\n",
        "  if maxindex is 0:  # baseline is the best\n",
        "    return None\n",
        "  else:              # find proper k (-1 is ok cause of 0 index is for baseline)\n",
        "    return ks[maxindex-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mOJoGdjQhMlP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "from itertools import chain\n",
        "from random import shuffle\n",
        "\n",
        "# Helper function; Simulate unfair coin flip\n",
        "def flip_a_unfair_coin(p): # p is for example 3/10 etc.\n",
        "  return random.random()<p\n",
        "\n",
        "# Hardcoded split 90%:10%\n",
        "# Get images and labels of some writer, and create 90%:10% split\n",
        "# return images and labels (same list) and also m (border line: [0, m), [m, n) split)\n",
        "def stratify_me(images, labels):\n",
        "  X_train = []  # train:test = 90%:10% of writer images\n",
        "  X_test = []\n",
        "  y_train = []\n",
        "  y_test = []\n",
        "  \n",
        "  indexlabels = [i for i in chain(range(ord('0'), ord('9')+1), range(ord('A'), ord('Z')+1), range(ord('a'), ord('z')+1))]  # [48, 49, 50, ..., 65, 66, ..., 97, 98, ...]\n",
        "  freqlabels = [[] for _ in indexlabels]  # 0-9, A-Z, a-z\n",
        "  \n",
        "  n = len(labels)  # size of writer pictures\n",
        "  m = 0            # border for dynamic history ~int(0.9*n)+1\n",
        "  \n",
        "  for i in range(len(labels)):\n",
        "    indx = indexlabels.index(int(labels[i]))  # position in freqlabels with respect to ascii code of label\n",
        "    freqlabels[indx].append(i)                # freqlabels[ascii_code_of_0] contains all indexes for label '0' in writer images\n",
        "    \n",
        "  for freq in freqlabels:\n",
        "    shuffle(freq)\n",
        "    \n",
        "    # first part, enough label\n",
        "    while len(freq)>=10:\n",
        "      _freq = freq[:10]\n",
        "      freq = freq[10:]\n",
        "      \n",
        "                                       # random choose one of ten images for evaluation (I can choose one index, but I want to shuffle also for dynamic history)\n",
        "      X_test.append(images[_freq[0]])  # add one image for evaluation set\n",
        "      y_test.append(labels[_freq[0]])\n",
        "      for f in _freq[1:]:\n",
        "        X_train.append(images[f])  # add nine images to dynamic istory set\n",
        "        y_train.append(labels[f])\n",
        "      m += 9                              # added nine images into dynamic history\n",
        "    \n",
        "    # second part, should I sample from tail (example 3 images instead of 10)\n",
        "    if flip_a_unfair_coin(len(freq)/10)==True:\n",
        "      X_test.append(images[freq[0]])\n",
        "      y_test.append(labels[freq[0]])\n",
        "      freq = freq[1:]\n",
        "      \n",
        "    for f in freq:\n",
        "      X_train.append(images[f])\n",
        "      y_train.append(labels[f])\n",
        "    m += len(freq)  # added rest of the images into dynamic history set\n",
        "    \n",
        "  return X_train+X_test, y_train+y_test, m, n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcaVScAnfCWG",
        "colab_type": "code",
        "outputId": "930f577a-f338-4285-d9f1-73c06743dd83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2380
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for writer in TESTDATA.keys():   # [2, 665, 1369]: writer - current writer id\n",
        "  #images9 = TESTDATA[writer][0]  # images9 - images of current writer\n",
        "  #labels9 = TESTDATA[writer][1]  # labels9 - labels of current writer\n",
        "  #n = len(images9)               \n",
        "  #m = int(0.90*n)+1                 # 90% for dynaminc history, 10% for evaluation of new model\n",
        "  images9, labels9, m, n = stratify_me(TESTDATA[writer][0], OH_L.decode_all(TESTDATA[writer][1]))\n",
        "  \n",
        "  \n",
        "  #################################################### GET DYNAMIC HISTORY {(predicted_label, original_label):[[vector], count]}\n",
        "  history = {}\n",
        "  for i in range(0, m):\n",
        "    original_label = int(labels9[i])\n",
        "    predicted_label = int(OH_L.decode(recognizer.predict(np.array([images9[i]]))[0]))\n",
        "    predicted_vector = find_minimal(original_label, finder.predict(np.array([images9[i]]))[0])  \n",
        "    if (predicted_label, original_label) not in history.keys():\n",
        "      history[(predicted_label, original_label)]=[predicted_vector, 1]\n",
        "    else:\n",
        "      history[(predicted_label, original_label)][0] += predicted_vector\n",
        "      history[(predicted_label, original_label)][1] += 1      \n",
        "  for (x,y) in sorted(history.keys()):  # find AVG of predicted clusters; DROP THIS PART IN NEW VERSION; MLADEN IDEA\n",
        "    history[(x,y)][0] /= history[(x,y)][1]  \n",
        "  \n",
        "  #################################################### GET SPECTARS\n",
        "  writer_network_spectar = {}\n",
        "  writer_knn_spectars = {}  # dict of dictionaries\n",
        "  for k in ks:\n",
        "    writer_knn_spectars[k] = {}  # spectars for each k in ks\n",
        "  for l in labels:   # add statistic for character l to all spectars\n",
        "    writer_network_spectar[l] = CharStatistic(l) # [0, 0]\n",
        "    for k in ks:\n",
        "      writer_knn_spectars[k][l] = CharStatistic(l)\n",
        "    \n",
        "  for i in range(0, m):\n",
        "    original_label = int(labels9[i])\n",
        "    predicted_label = int(OH_L.decode(recognizer.predict(np.array([images9[i]]))[0]))\n",
        "    predicted_vector = finder.predict(np.array([images9[i]]))[0]\n",
        "    \n",
        "    ##### writer_network_spectar\n",
        "    if original_label == predicted_label:\n",
        "      writer_network_spectar[chr(predicted_label)].update_one(1) # Network says predicted_label and its correct\n",
        "    else:\n",
        "      writer_network_spectar[chr(predicted_label)].update_one(0)  # Network says predicted_label and its wrong\n",
        "         \n",
        "    ##### writer_knn_spectar\n",
        "    min_labels = get_min_label(history, predicted_vector)\n",
        "    for k in ks:  # get min label is configured with respect to ks\n",
        "      min_label = min_labels[k]\n",
        "      if min_label is None:\n",
        "        min_label = predicted_label  # min label je moje predvidjanje \n",
        "      if min_label == original_label:  # min_label je ono sto ja predvidjam na onih 10%; to i evaluiram \n",
        "        writer_knn_spectars[k][chr(min_label)].update_one(1)\n",
        "      else:\n",
        "        writer_knn_spectars[k][chr(min_label)].update_one(0)\n",
        "  \n",
        "  #################################################### GET S AND S1\n",
        "  S = 0\n",
        "  S1 = 0\n",
        "  Sboth = 0\n",
        "  N = len(labels9[m:n])\n",
        "  for i in range(m, n):  # slow variant\n",
        "    original_label = int(labels9[i])\n",
        "    predicted_label = int(OH_L.decode(recognizer.predict(np.array([images9[i]]))[0])) # int(string like '48') -> ascii code\n",
        "    predicted_vector = finder.predict(np.array([images9[i]]))[0]\n",
        "    \n",
        "    ##### S1; old one\n",
        "    #print('NN DEBUG: predicted: ', predicted_label, 'original: ', original_label)\n",
        "    #input()\n",
        "    if predicted_label == original_label:\n",
        "      S1 += 1\n",
        "    predicted_label_bkp = predicted_label\n",
        "    ##### S; new approach\n",
        "    min_labels = get_min_label(history, predicted_vector)  # get list of predictions or each k\n",
        "    k = who_to_believe(predicted_label, writer_network_spectar, min_labels, writer_knn_spectars)  # Choose who have biggest mean of all spectars, use it as a aprediction\n",
        "    if k is not None and min_labels[k] is not None:  # believe to specific knn, which have it own prediction\n",
        "      predicted_label = min_labels[k]  # new approach; change network prediction if knn is sure enough  \n",
        "    if predicted_label == original_label:\n",
        "      S += 1\n",
        "  \n",
        "    ##### Sboth\n",
        "    if predicted_label_bkp == original_label or (k is not None and min_labels[k] is not None and min_labels[k]==original_label):\n",
        "      Sboth+=1 \n",
        "  \n",
        "    ########## UPDATE history AND *spectar ##########\n",
        "    # original_label OK\n",
        "    predicted_label = predicted_label_bkp\n",
        "    # predicted_vector OK \n",
        "    \n",
        "    # history\n",
        "    predicted_vector_bkp = find_minimal(original_label, predicted_vector)\n",
        "    if (predicted_label, original_label) not in history.keys():\n",
        "      history[(predicted_label, original_label)]=[predicted_vector_bkp, 1]\n",
        "    else:\n",
        "      history[(predicted_label, original_label)][0] = (history[(predicted_label, original_label)][0]*history[(predicted_label, original_label)][1]+predicted_vector_bkp)/(history[(predicted_label, original_label)][1]+1)\n",
        "      history[(predicted_label, original_label)][1] += 1\n",
        "    \n",
        "    # writer_network_spectar\n",
        "    if original_label == predicted_label:\n",
        "      writer_network_spectar[chr(predicted_label)].update_one(1)  # Network says predicted_label and its correct\n",
        "    else:\n",
        "      writer_network_spectar[chr(predicted_label)].update_one(0)  # Network says predicted_label and its wrong\n",
        "  \n",
        "    # writer_knn_spectar\n",
        "    min_labels = get_min_label(history, predicted_vector)  # prvo ga ubacim u istoriju - ali kao proseci itd. a onda kasnije trazim min_label; MOZDA INVERZNO? da ne bih nasao istog\n",
        "    for k in ks:\n",
        "      min_label = min_labels[k]\n",
        "      if min_label is None:\n",
        "        min_label = predicted_label  # min label je moje predvidjanje \n",
        "      if min_label == original_label:  # min_label je ono sto ja predvidjam na onih 10%; to i evaluiram \n",
        "        writer_knn_spectars[k][chr(min_label)].update_one(1)\n",
        "      else:\n",
        "        writer_knn_spectars[k][chr(min_label)].update_one(0)\n",
        "    ########## END UPDATE ##########\n",
        "    \n",
        "  #################################################### PRINT AND UPDATE GLOBAL VALUES\n",
        "  if S!=S1:  # Print only diff\n",
        "    print(\"Writer {0:4d} == mynew: {1:d} ({2:3.2f}%) == old: {3:d} ({4:3.2f}%) == both: {5:d} ({6:3.2f}%), No. of images {7:d}, len(image9)={8:d}\".format(writer, S, float(100*S)/N, S1, float(100*S1)/N, Sboth, float(100.0*Sboth)/N, N, n))\n",
        "  sumS += S\n",
        "  sumS1 += S1\n",
        "  sumSboth += Sboth\n",
        "  sumN += N   \n",
        "  \n",
        "  if S==S1:\n",
        "    equal += 1\n",
        "  elif S>S1:\n",
        "    winnew += 1\n",
        "    lenBetterNew += n\n",
        "  else:\n",
        "    winold += 1\n",
        "    lenBetterOld += n   \n",
        "    \n",
        "  del history\n",
        "  del writer_network_spectar\n",
        "  del writer_knn_spectars"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writer    1 == mynew: 37 (86.05%) == old: 35 (81.40%) == both: 37 (86.05%), No. of images 43, len(image9)=413\n",
            "Writer    2 == mynew: 35 (87.50%) == old: 33 (82.50%) == both: 35 (87.50%), No. of images 40, len(image9)=404\n",
            "Writer    3 == mynew: 40 (90.91%) == old: 36 (81.82%) == both: 40 (90.91%), No. of images 44, len(image9)=397\n",
            "Writer  518 == mynew: 40 (95.24%) == old: 37 (88.10%) == both: 40 (95.24%), No. of images 42, len(image9)=403\n",
            "Writer  519 == mynew: 35 (89.74%) == old: 33 (84.62%) == both: 36 (92.31%), No. of images 39, len(image9)=394\n",
            "Writer   10 == mynew: 41 (91.11%) == old: 40 (88.89%) == both: 41 (91.11%), No. of images 45, len(image9)=436\n",
            "Writer   17 == mynew: 38 (86.36%) == old: 41 (93.18%) == both: 41 (93.18%), No. of images 44, len(image9)=424\n",
            "Writer  530 == mynew: 29 (80.56%) == old: 30 (83.33%) == both: 32 (88.89%), No. of images 36, len(image9)=408\n",
            "Writer   23 == mynew: 41 (85.42%) == old: 46 (95.83%) == both: 46 (95.83%), No. of images 48, len(image9)=418\n",
            "Writer   27 == mynew: 36 (80.00%) == old: 34 (75.56%) == both: 36 (80.00%), No. of images 45, len(image9)=446\n",
            "Writer   28 == mynew: 31 (77.50%) == old: 33 (82.50%) == both: 34 (85.00%), No. of images 40, len(image9)=399\n",
            "Writer   31 == mynew: 33 (82.50%) == old: 31 (77.50%) == both: 33 (82.50%), No. of images 40, len(image9)=407\n",
            "Writer  547 == mynew: 39 (92.86%) == old: 36 (85.71%) == both: 40 (95.24%), No. of images 42, len(image9)=415\n",
            "Writer   35 == mynew: 41 (93.18%) == old: 39 (88.64%) == both: 42 (95.45%), No. of images 44, len(image9)=416\n",
            "Writer  554 == mynew: 35 (85.37%) == old: 34 (82.93%) == both: 35 (85.37%), No. of images 41, len(image9)=393\n",
            "Writer   46 == mynew: 34 (89.47%) == old: 32 (84.21%) == both: 34 (89.47%), No. of images 38, len(image9)=430\n",
            "Writer   47 == mynew: 36 (92.31%) == old: 33 (84.62%) == both: 36 (92.31%), No. of images 39, len(image9)=395\n",
            "Writer  559 == mynew: 34 (87.18%) == old: 32 (82.05%) == both: 35 (89.74%), No. of images 39, len(image9)=406\n",
            "Writer   49 == mynew: 37 (94.87%) == old: 33 (84.62%) == both: 37 (94.87%), No. of images 39, len(image9)=393\n",
            "Writer   51 == mynew: 37 (88.10%) == old: 36 (85.71%) == both: 38 (90.48%), No. of images 42, len(image9)=396\n",
            "Writer 1091 == mynew: 40 (90.91%) == old: 39 (88.64%) == both: 41 (93.18%), No. of images 44, len(image9)=411\n",
            "Writer   70 == mynew: 39 (84.78%) == old: 37 (80.43%) == both: 40 (86.96%), No. of images 46, len(image9)=433\n",
            "Writer   77 == mynew: 38 (92.68%) == old: 37 (90.24%) == both: 40 (97.56%), No. of images 41, len(image9)=409\n",
            "Writer  596 == mynew: 16 (39.02%) == old: 18 (43.90%) == both: 18 (43.90%), No. of images 41, len(image9)=393\n",
            "Writer  597 == mynew: 34 (94.44%) == old: 32 (88.89%) == both: 35 (97.22%), No. of images 36, len(image9)=398\n",
            "Writer 1112 == mynew: 33 (94.29%) == old: 32 (91.43%) == both: 33 (94.29%), No. of images 35, len(image9)=389\n",
            "Writer   90 == mynew: 38 (86.36%) == old: 35 (79.55%) == both: 39 (88.64%), No. of images 44, len(image9)=403\n",
            "Writer   94 == mynew: 41 (91.11%) == old: 40 (88.89%) == both: 43 (95.56%), No. of images 45, len(image9)=410\n",
            "Writer   95 == mynew: 34 (91.89%) == old: 33 (89.19%) == both: 34 (91.89%), No. of images 37, len(image9)=403\n",
            "Writer   96 == mynew: 32 (96.97%) == old: 30 (90.91%) == both: 32 (96.97%), No. of images 33, len(image9)=399\n",
            "Writer 1120 == mynew: 37 (92.50%) == old: 36 (90.00%) == both: 37 (92.50%), No. of images 40, len(image9)=400\n",
            "Writer   99 == mynew: 38 (92.68%) == old: 35 (85.37%) == both: 38 (92.68%), No. of images 41, len(image9)=423\n",
            "Writer  613 == mynew: 38 (84.44%) == old: 39 (86.67%) == both: 39 (86.67%), No. of images 45, len(image9)=416\n",
            "Writer  622 == mynew: 37 (88.10%) == old: 38 (90.48%) == both: 38 (90.48%), No. of images 42, len(image9)=410\n",
            "Writer  112 == mynew: 35 (94.59%) == old: 36 (97.30%) == both: 36 (97.30%), No. of images 37, len(image9)=396\n",
            "Writer  115 == mynew: 40 (88.89%) == old: 38 (84.44%) == both: 41 (91.11%), No. of images 45, len(image9)=421\n",
            "Writer  118 == mynew: 38 (90.48%) == old: 37 (88.10%) == both: 38 (90.48%), No. of images 42, len(image9)=408\n",
            "Writer  119 == mynew: 39 (97.50%) == old: 35 (87.50%) == both: 39 (97.50%), No. of images 40, len(image9)=437\n",
            "Writer  644 == mynew: 36 (85.71%) == old: 32 (76.19%) == both: 36 (85.71%), No. of images 42, len(image9)=436\n",
            "Writer  137 == mynew: 35 (89.74%) == old: 36 (92.31%) == both: 37 (94.87%), No. of images 39, len(image9)=395\n",
            "Writer  141 == mynew: 36 (97.30%) == old: 32 (86.49%) == both: 36 (97.30%), No. of images 37, len(image9)=390\n",
            "Writer  143 == mynew: 38 (90.48%) == old: 35 (83.33%) == both: 39 (92.86%), No. of images 42, len(image9)=395\n",
            "Writer  155 == mynew: 36 (83.72%) == old: 34 (79.07%) == both: 36 (83.72%), No. of images 43, len(image9)=442\n",
            "Writer  158 == mynew: 39 (95.12%) == old: 38 (92.68%) == both: 39 (95.12%), No. of images 41, len(image9)=390\n",
            "Writer  159 == mynew: 32 (91.43%) == old: 31 (88.57%) == both: 33 (94.29%), No. of images 35, len(image9)=396\n",
            "Writer  161 == mynew: 41 (93.18%) == old: 38 (86.36%) == both: 41 (93.18%), No. of images 44, len(image9)=415\n",
            "Writer  163 == mynew: 37 (88.10%) == old: 34 (80.95%) == both: 37 (88.10%), No. of images 42, len(image9)=404\n",
            "Writer  679 == mynew: 39 (97.50%) == old: 37 (92.50%) == both: 39 (97.50%), No. of images 40, len(image9)=415\n",
            "Writer  170 == mynew: 32 (91.43%) == old: 29 (82.86%) == both: 33 (94.29%), No. of images 35, len(image9)=389\n",
            "Writer  171 == mynew: 38 (95.00%) == old: 37 (92.50%) == both: 39 (97.50%), No. of images 40, len(image9)=394\n",
            "Writer  687 == mynew: 37 (94.87%) == old: 33 (84.62%) == both: 37 (94.87%), No. of images 39, len(image9)=392\n",
            "Writer  185 == mynew: 33 (84.62%) == old: 31 (79.49%) == both: 33 (84.62%), No. of images 39, len(image9)=394\n",
            "Writer  698 == mynew: 37 (92.50%) == old: 35 (87.50%) == both: 37 (92.50%), No. of images 40, len(image9)=415\n",
            "Writer  699 == mynew: 36 (90.00%) == old: 35 (87.50%) == both: 36 (90.00%), No. of images 40, len(image9)=401\n",
            "Writer  188 == mynew: 35 (87.50%) == old: 36 (90.00%) == both: 38 (95.00%), No. of images 40, len(image9)=401\n",
            "Writer  187 == mynew: 33 (89.19%) == old: 32 (86.49%) == both: 34 (91.89%), No. of images 37, len(image9)=414\n",
            "Writer  706 == mynew: 34 (87.18%) == old: 31 (79.49%) == both: 35 (89.74%), No. of images 39, len(image9)=403\n",
            "Writer  199 == mynew: 38 (86.36%) == old: 35 (79.55%) == both: 38 (86.36%), No. of images 44, len(image9)=433\n",
            "Writer  203 == mynew: 43 (93.48%) == old: 41 (89.13%) == both: 43 (93.48%), No. of images 46, len(image9)=426\n",
            "Writer  717 == mynew: 35 (97.22%) == old: 34 (94.44%) == both: 35 (97.22%), No. of images 36, len(image9)=391\n",
            "Writer  207 == mynew: 34 (94.44%) == old: 31 (86.11%) == both: 34 (94.44%), No. of images 36, len(image9)=391\n",
            "Writer 1233 == mynew: 39 (97.50%) == old: 38 (95.00%) == both: 39 (97.50%), No. of images 40, len(image9)=395\n",
            "Writer  219 == mynew: 33 (80.49%) == old: 32 (78.05%) == both: 33 (80.49%), No. of images 41, len(image9)=403\n",
            "Writer  224 == mynew: 34 (82.93%) == old: 33 (80.49%) == both: 36 (87.80%), No. of images 41, len(image9)=396\n",
            "Writer  743 == mynew: 35 (85.37%) == old: 34 (82.93%) == both: 36 (87.80%), No. of images 41, len(image9)=425\n",
            "Writer  750 == mynew: 36 (94.74%) == old: 35 (92.11%) == both: 36 (94.74%), No. of images 38, len(image9)=399\n",
            "Writer  751 == mynew: 37 (86.05%) == old: 35 (81.40%) == both: 37 (86.05%), No. of images 43, len(image9)=392\n",
            "Writer  752 == mynew: 32 (88.89%) == old: 31 (86.11%) == both: 33 (91.67%), No. of images 36, len(image9)=407\n",
            "Writer  241 == mynew: 35 (94.59%) == old: 34 (91.89%) == both: 35 (94.59%), No. of images 37, len(image9)=395\n",
            "Writer  240 == mynew: 37 (94.87%) == old: 36 (92.31%) == both: 37 (94.87%), No. of images 39, len(image9)=389\n",
            "Writer  242 == mynew: 30 (85.71%) == old: 27 (77.14%) == both: 30 (85.71%), No. of images 35, len(image9)=404\n",
            "Writer  765 == mynew: 35 (92.11%) == old: 32 (84.21%) == both: 35 (92.11%), No. of images 38, len(image9)=400\n",
            "Writer  254 == mynew: 37 (92.50%) == old: 36 (90.00%) == both: 37 (92.50%), No. of images 40, len(image9)=429\n",
            "Writer  255 == mynew: 37 (88.10%) == old: 34 (80.95%) == both: 38 (90.48%), No. of images 42, len(image9)=418\n",
            "Writer 1277 == mynew: 37 (86.05%) == old: 35 (81.40%) == both: 38 (88.37%), No. of images 43, len(image9)=399\n",
            "Writer 1282 == mynew: 35 (89.74%) == old: 34 (87.18%) == both: 36 (92.31%), No. of images 39, len(image9)=395\n",
            "Writer  258 == mynew: 29 (80.56%) == old: 28 (77.78%) == both: 31 (86.11%), No. of images 36, len(image9)=394\n",
            "Writer  261 == mynew: 55 (91.67%) == old: 54 (90.00%) == both: 56 (93.33%), No. of images 60, len(image9)=583\n",
            "Writer  271 == mynew: 34 (89.47%) == old: 35 (92.11%) == both: 35 (92.11%), No. of images 38, len(image9)=393\n",
            "Writer 1301 == mynew: 38 (95.00%) == old: 37 (92.50%) == both: 38 (95.00%), No. of images 40, len(image9)=435\n",
            "Writer  278 == mynew: 39 (90.70%) == old: 38 (88.37%) == both: 40 (93.02%), No. of images 43, len(image9)=397\n",
            "Writer  281 == mynew: 43 (93.48%) == old: 40 (86.96%) == both: 43 (93.48%), No. of images 46, len(image9)=424\n",
            "Writer  284 == mynew: 33 (94.29%) == old: 31 (88.57%) == both: 33 (94.29%), No. of images 35, len(image9)=405\n",
            "Writer  287 == mynew: 34 (91.89%) == old: 33 (89.19%) == both: 34 (91.89%), No. of images 37, len(image9)=401\n",
            "Writer  289 == mynew: 37 (77.08%) == old: 36 (75.00%) == both: 38 (79.17%), No. of images 48, len(image9)=464\n",
            "Writer  292 == mynew: 40 (83.33%) == old: 38 (79.17%) == both: 41 (85.42%), No. of images 48, len(image9)=442\n",
            "Writer  296 == mynew: 41 (95.35%) == old: 38 (88.37%) == both: 41 (95.35%), No. of images 43, len(image9)=397\n",
            "Writer  302 == mynew: 32 (88.89%) == old: 30 (83.33%) == both: 33 (91.67%), No. of images 36, len(image9)=399\n",
            "Writer  815 == mynew: 39 (97.50%) == old: 36 (90.00%) == both: 39 (97.50%), No. of images 40, len(image9)=407\n",
            "Writer  312 == mynew: 39 (90.70%) == old: 37 (86.05%) == both: 39 (90.70%), No. of images 43, len(image9)=416\n",
            "Writer  834 == mynew: 42 (87.50%) == old: 38 (79.17%) == both: 42 (87.50%), No. of images 48, len(image9)=397\n",
            "Writer  327 == mynew: 37 (97.37%) == old: 33 (86.84%) == both: 37 (97.37%), No. of images 38, len(image9)=403\n",
            "Writer  328 == mynew: 34 (80.95%) == old: 35 (83.33%) == both: 36 (85.71%), No. of images 42, len(image9)=411\n",
            "Writer  330 == mynew: 41 (93.18%) == old: 38 (86.36%) == both: 42 (95.45%), No. of images 44, len(image9)=417\n",
            "Writer  843 == mynew: 36 (97.30%) == old: 35 (94.59%) == both: 36 (97.30%), No. of images 37, len(image9)=414\n",
            "Writer  841 == mynew: 35 (89.74%) == old: 33 (84.62%) == both: 36 (92.31%), No. of images 39, len(image9)=389\n",
            "Writer  337 == mynew: 40 (93.02%) == old: 38 (88.37%) == both: 40 (93.02%), No. of images 43, len(image9)=435\n",
            "Writer  345 == mynew: 36 (92.31%) == old: 35 (89.74%) == both: 37 (94.87%), No. of images 39, len(image9)=389\n",
            "Writer 1369 == mynew: 35 (94.59%) == old: 33 (89.19%) == both: 35 (94.59%), No. of images 37, len(image9)=422\n",
            "Writer  347 == mynew: 36 (85.71%) == old: 37 (88.10%) == both: 37 (88.10%), No. of images 42, len(image9)=412\n",
            "Writer  860 == mynew: 37 (88.10%) == old: 35 (83.33%) == both: 38 (90.48%), No. of images 42, len(image9)=396\n",
            "Writer  863 == mynew: 35 (89.74%) == old: 36 (92.31%) == both: 36 (92.31%), No. of images 39, len(image9)=422\n",
            "Writer  865 == mynew: 39 (95.12%) == old: 37 (90.24%) == both: 39 (95.12%), No. of images 41, len(image9)=392\n",
            "Writer  359 == mynew: 35 (92.11%) == old: 31 (81.58%) == both: 35 (92.11%), No. of images 38, len(image9)=400\n",
            "Writer  360 == mynew: 40 (88.89%) == old: 39 (86.67%) == both: 42 (93.33%), No. of images 45, len(image9)=420\n",
            "Writer  361 == mynew: 38 (90.48%) == old: 36 (85.71%) == both: 38 (90.48%), No. of images 42, len(image9)=415\n",
            "Writer  876 == mynew: 38 (86.36%) == old: 37 (84.09%) == both: 38 (86.36%), No. of images 44, len(image9)=397\n",
            "Writer  877 == mynew: 34 (85.00%) == old: 35 (87.50%) == both: 35 (87.50%), No. of images 40, len(image9)=394\n",
            "Writer  379 == mynew: 37 (86.05%) == old: 36 (83.72%) == both: 38 (88.37%), No. of images 43, len(image9)=418\n",
            "Writer  902 == mynew: 37 (94.87%) == old: 36 (92.31%) == both: 38 (97.44%), No. of images 39, len(image9)=392\n",
            "Writer  392 == mynew: 39 (92.86%) == old: 37 (88.10%) == both: 39 (92.86%), No. of images 42, len(image9)=392\n",
            "Writer  914 == mynew: 36 (92.31%) == old: 35 (89.74%) == both: 36 (92.31%), No. of images 39, len(image9)=402\n",
            "Writer  402 == mynew: 33 (91.67%) == old: 31 (86.11%) == both: 33 (91.67%), No. of images 36, len(image9)=390\n",
            "Writer  403 == mynew: 40 (95.24%) == old: 38 (90.48%) == both: 41 (97.62%), No. of images 42, len(image9)=397\n",
            "Writer  919 == mynew: 32 (94.12%) == old: 31 (91.18%) == both: 32 (94.12%), No. of images 34, len(image9)=393\n",
            "Writer  409 == mynew: 40 (93.02%) == old: 39 (90.70%) == both: 41 (95.35%), No. of images 43, len(image9)=404\n",
            "Writer  925 == mynew: 39 (90.70%) == old: 37 (86.05%) == both: 39 (90.70%), No. of images 43, len(image9)=413\n",
            "Writer  931 == mynew: 32 (94.12%) == old: 30 (88.24%) == both: 32 (94.12%), No. of images 34, len(image9)=396\n",
            "Writer  431 == mynew: 35 (85.37%) == old: 34 (82.93%) == both: 35 (85.37%), No. of images 41, len(image9)=402\n",
            "Writer  943 == mynew: 38 (88.37%) == old: 40 (93.02%) == both: 40 (93.02%), No. of images 43, len(image9)=393\n",
            "Writer  951 == mynew: 39 (92.86%) == old: 36 (85.71%) == both: 39 (92.86%), No. of images 42, len(image9)=395\n",
            "Writer  443 == mynew: 40 (93.02%) == old: 39 (90.70%) == both: 41 (95.35%), No. of images 43, len(image9)=417\n",
            "Writer  444 == mynew: 37 (92.50%) == old: 38 (95.00%) == both: 38 (95.00%), No. of images 40, len(image9)=406\n",
            "Writer  445 == mynew: 35 (89.74%) == old: 33 (84.62%) == both: 36 (92.31%), No. of images 39, len(image9)=402\n",
            "Writer  961 == mynew: 28 (84.85%) == old: 25 (75.76%) == both: 29 (87.88%), No. of images 33, len(image9)=402\n",
            "Writer  451 == mynew: 44 (88.00%) == old: 43 (86.00%) == both: 45 (90.00%), No. of images 50, len(image9)=419\n",
            "Writer  453 == mynew: 37 (94.87%) == old: 38 (97.44%) == both: 38 (97.44%), No. of images 39, len(image9)=392\n",
            "Writer  461 == mynew: 32 (94.12%) == old: 29 (85.29%) == both: 32 (94.12%), No. of images 34, len(image9)=402\n",
            "Writer  465 == mynew: 36 (92.31%) == old: 35 (89.74%) == both: 36 (92.31%), No. of images 39, len(image9)=420\n",
            "Writer  466 == mynew: 40 (97.56%) == old: 39 (95.12%) == both: 41 (100.00%), No. of images 41, len(image9)=401\n",
            "Writer  468 == mynew: 32 (86.49%) == old: 31 (83.78%) == both: 32 (86.49%), No. of images 37, len(image9)=405\n",
            "Writer  477 == mynew: 38 (90.48%) == old: 37 (88.10%) == both: 39 (92.86%), No. of images 42, len(image9)=391\n",
            "Writer  989 == mynew: 39 (95.12%) == old: 37 (90.24%) == both: 40 (97.56%), No. of images 41, len(image9)=398\n",
            "Writer  991 == mynew: 37 (86.05%) == old: 34 (79.07%) == both: 38 (88.37%), No. of images 43, len(image9)=397\n",
            "Writer  996 == mynew: 36 (90.00%) == old: 34 (85.00%) == both: 36 (90.00%), No. of images 40, len(image9)=419\n",
            "Writer  494 == mynew: 36 (92.31%) == old: 33 (84.62%) == both: 36 (92.31%), No. of images 39, len(image9)=412\n",
            "Writer  502 == mynew: 34 (89.47%) == old: 33 (86.84%) == both: 34 (89.47%), No. of images 38, len(image9)=393\n",
            "CPU times: user 21min 1s, sys: 1min 3s, total: 22min 4s\n",
            "Wall time: 17min 54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M2ERmd5MfCLM",
        "colab_type": "code",
        "outputId": "fba0da73-d88a-4933-d707-a98a57f0cb77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "print('winold: ', winold)\n",
        "print('equal: ', equal)\n",
        "print('winnew: ', winnew)\n",
        "print('S: (new): ', 100.0*sumS/sumN)\n",
        "print('S1: (old): ', 100.0*sumS1/sumN)\n",
        "print('Sboth: (new): ', 100.0*sumSboth/sumN)\n",
        "print('AVG len winold: ', 1.0*lenBetterOld/winold)\n",
        "print('AVG len winnew: ', 1.0*lenBetterNew/winnew)\n",
        "print('No of evaluation images: ', sumN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "winold:  18\n",
            "equal:  63\n",
            "winnew:  119\n",
            "S: (new):  89.61552725924095\n",
            "S1: (old):  87.09358387934232\n",
            "Sboth: (new):  91.23501050809742\n",
            "AVG len winold:  404.6111111111111\n",
            "AVG len winnew:  408.25210084033614\n",
            "No of evaluation images:  8089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Z_xv4JBRozo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# +2.52%/+4.14%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XyYbvCXFhou_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# With Stratify, multiple k idea, RESAMPLE"
      ]
    },
    {
      "metadata": {
        "id": "LwmowrbGhr8q",
        "colab_type": "code",
        "outputId": "76ebe9e3-a977-467b-a39e-6b1d89e55007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "for char in range(ord('0'), ord('9')+1):\n",
        "  labels.append(chr(char))\n",
        "for char in range(ord('A'), ord('Z')+1):\n",
        "  labels.append(chr(char))\n",
        "for char in range(ord('a'), ord('z')+1):\n",
        "  labels.append(chr(char))\n",
        "print(labels)  \n",
        "print(len(labels))\n",
        "\n",
        "testset = set(test_Writers)\n",
        "print(len(testset))  # No of different writers\n",
        "\n",
        "# TESTDATA[Writer] = [testImagesOfWriter, testLabelsOfWriter]; example: TESTDATA[9] = [testImages9, testLabels9]\n",
        "TESTDATA = {} \n",
        "for writer in testset:\n",
        "  TESTDATA[writer] = [[], []]\n",
        "for i in range(0, len(test_Writers)):\n",
        "    TESTDATA[test_Writers[i]][0].append(test_Images[i])\n",
        "    TESTDATA[test_Writers[i]][1].append(test_Labels[i])\n",
        "\n",
        "def find_minimal(i, vector):  # i is the ascii code: 48.49,...,65,66,...,97,...\n",
        "  # Implicit use of dictionary ICentroids[ASCII]\n",
        "  minindex = 0\n",
        "  mineps = np.linalg.norm(vector-ICentroids[i][0])\n",
        "  for j in range(1, ICentroids[i].shape[0]):  \n",
        "    _mineps = np.linalg.norm(vector-ICentroids[i][j])\n",
        "    if _mineps < mineps:\n",
        "      mineps = _mineps\n",
        "      minindex = j\n",
        "      \n",
        "  return ICentroids[i][minindex].copy()   # CHANGE NUMBER OF CLUSTERS MLADEN IDEA"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "62\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "atFbqUaAhxjw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "winold = 0\n",
        "equal = 0\n",
        "winnew = 0\n",
        "sumS = 0\n",
        "sumS1 = 0\n",
        "sumSboth = 0\n",
        "sumN = 0\n",
        "lenBetterOld = 0\n",
        "lenBetterNew = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iDuGdIKvhxV9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "ks = [2,4,6,8,10]  # outer object for configure get_min_label function and evaluation\n",
        "\n",
        "def get_min_label(history, predicted_vector): # return list of predicted label for k in ks\n",
        "  X_search = []\n",
        "  y_search = []\n",
        "  for (_predicted_label, _original_label) in history.keys():  # Na 90% mreza je rekla _predicted_label a bila je _original_label (imam vector i count)\n",
        "      if _predicted_label == predicted_label:\n",
        "        for _ in range(history[(_predicted_label, _original_label)][1]):\n",
        "          X_search.append(history[(_predicted_label, _original_label)][0])\n",
        "          y_search.append(_original_label)      \n",
        "  \n",
        "  results = {}\n",
        "  for k in ks:\n",
        "    if len(X_search)<k:  # if I cant do knn search with respect to specific k\n",
        "      results[k] = None\n",
        "    else:\n",
        "      knn = KNeighborsClassifier(n_neighbors=k, metric='l2')  # empirically confirm; use heuristic instead of min\n",
        "      knn.fit(X_search, y_search)\n",
        "      results[k] = knn.predict(np.array([predicted_vector]))[0]\n",
        "      \n",
        "  return results # return dict of predictions for each k in ks [1, 2, 4, 6, 8]\n",
        "\n",
        "# Who to believe in prediction\n",
        "# input: (baseline prediction, baseline spectar, knns oredictions, knns spectars)\n",
        "def who_to_believe(predicted_label, writer_network_spectar, min_labels, writer_knn_spectars): # Return optimal k or None if baseline is the best\n",
        "  trust = [writer_network_spectar[chr(predicted_label)].get_mean()]\n",
        "  for k in ks:\n",
        "    if min_labels[k] is None: # no prediction for that k\n",
        "      trust.append(-1)  # baseline is above 0 in any case\n",
        "    else:\n",
        "      trust.append(writer_knn_spectars[k][chr(min_labels[k])].get_mean())  # mean of density approximation for predicted label for specific k \n",
        "    \n",
        "  maxindex = trust.index(max(trust))\n",
        "  if maxindex is 0:  # baseline is the best\n",
        "    return None\n",
        "  else:              # find proper k (-1 is ok cause of 0 index is for baseline)\n",
        "    return ks[maxindex-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "84GWWT-aiVqZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "from itertools import chain\n",
        "from random import shuffle\n",
        "\n",
        "# Helper function; Simulate unfair coin flip\n",
        "def flip_a_unfair_coin(p): # p is for example 3/10 etc.\n",
        "  return random.random()<p\n",
        "\n",
        "# Hardcoded split 90%:10%\n",
        "# Get images and labels of some writer, and create 90%:10% split\n",
        "# return images and labels (same list) and also m (border line: [0, m), [m, n) split)\n",
        "def stratify_me(images, labels):\n",
        "  X_train = []  # train:test = 90%:10% of writer images\n",
        "  X_test = []\n",
        "  y_train = []\n",
        "  y_test = []\n",
        "  \n",
        "  indexlabels = [i for i in chain(range(ord('0'), ord('9')+1), range(ord('A'), ord('Z')+1), range(ord('a'), ord('z')+1))]  # [48, 49, 50, ..., 65, 66, ..., 97, 98, ...]\n",
        "  freqlabels = [[] for _ in indexlabels]  # 0-9, A-Z, a-z\n",
        "  \n",
        "  n = len(labels)  # size of writer pictures\n",
        "  m = 0            # border for dynamic history ~int(0.9*n)+1\n",
        "  \n",
        "  for i in range(len(labels)):\n",
        "    indx = indexlabels.index(int(labels[i]))  # position in freqlabels with respect to ascii code of label\n",
        "    freqlabels[indx].append(i)                # freqlabels[ascii_code_of_0] contains all indexes for label '0' in writer images\n",
        "    \n",
        "  for freq in freqlabels:\n",
        "    shuffle(freq)\n",
        "    \n",
        "    # first part, enough label\n",
        "    while len(freq)>=10:\n",
        "      _freq = freq[:10]\n",
        "      freq = freq[10:]\n",
        "      \n",
        "                                       # random choose one of ten images for evaluation (I can choose one index, but I want to shuffle also for dynamic history)\n",
        "      X_test.append(images[_freq[0]])  # add one image for evaluation set\n",
        "      y_test.append(labels[_freq[0]])\n",
        "      for f in _freq[1:]:\n",
        "        X_train.append(images[f])  # add nine images to dynamic istory set\n",
        "        y_train.append(labels[f])\n",
        "      m += 9                              # added nine images into dynamic history\n",
        "    \n",
        "    # second part, should I sample from tail (example 3 images instead of 10)\n",
        "    if flip_a_unfair_coin(len(freq)/10)==True:\n",
        "      X_test.append(images[freq[0]])\n",
        "      y_test.append(labels[freq[0]])\n",
        "      freq = freq[1:]\n",
        "      \n",
        "    for f in freq:\n",
        "      X_train.append(images[f])\n",
        "      y_train.append(labels[f])\n",
        "    m += len(freq)  # added rest of the images into dynamic history set\n",
        "    \n",
        "  return X_train+X_test, y_train+y_test, m, n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uLV7ht-qhxI1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NoResample = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u9RD7LQthw6v",
        "colab_type": "code",
        "outputId": "4d303c0c-e3cf-45c4-ed80-e9a2eeba4b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3298
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for writer in TESTDATA.keys():   # writer - current writer id\n",
        "  #images9 = TESTDATA[writer][0]  # images9 - images of current writer\n",
        "  #labels9 = TESTDATA[writer][1]  # labels9 - labels of current writer\n",
        "  #n = len(images9)               \n",
        "  #m = int(0.9*n)+1                 # 90% for dynaminc history, 10% for evaluation of new model\n",
        "  \n",
        "  S = 0      # no of images on which new method is correct\n",
        "  S1 = 0     # no of images on which baseline network is correct\n",
        "  Sboth = 0  # no of images on which either baseline or knn is correct\n",
        "  Nall = 0   # no of evaluation images\n",
        "  for _ in range(NoResample):  # Resample\n",
        "    #################################################### STRATIFY AND SHUFFLE INTERNALLY \n",
        "    images9, labels9, m, n = stratify_me(TESTDATA[writer][0], OH_L.decode_all(TESTDATA[writer][1]))\n",
        "    \n",
        "    #################################################### GET DYNAMIC HISTORY {(predicted_label, original_label):[[vector], count]}\n",
        "    history = {}\n",
        "    for i in range(0, m):\n",
        "      original_label = int(labels9[i])\n",
        "      predicted_label = int(OH_L.decode(recognizer.predict(np.array([images9[i]]))[0]))\n",
        "      predicted_vector = find_minimal(original_label, finder.predict(np.array([images9[i]]))[0])  \n",
        "      if (predicted_label, original_label) not in history.keys():\n",
        "        history[(predicted_label, original_label)]=[predicted_vector, 1]\n",
        "      else:\n",
        "        history[(predicted_label, original_label)][0] += predicted_vector\n",
        "        history[(predicted_label, original_label)][1] += 1      \n",
        "    for (x,y) in sorted(history.keys()):  # find AVG of predicted clusters\n",
        "      history[(x,y)][0] /= history[(x,y)][1]  \n",
        "  \n",
        "    #################################################### GET SPECTARS\n",
        "    writer_network_spectar = {}\n",
        "    writer_knn_spectars = {}  # dict of dictionaries\n",
        "    for k in ks:\n",
        "      writer_knn_spectars[k] = {}  # spectars for each k in ks\n",
        "    for l in labels:   # add statistic for character l to all spectars\n",
        "      writer_network_spectar[l] = CharStatistic(l) # [0, 0]\n",
        "      for k in ks:\n",
        "        writer_knn_spectars[k][l] = CharStatistic(l)\n",
        "    \n",
        "    for i in range(0, m):\n",
        "      original_label = int(labels9[i])\n",
        "      predicted_label = int(OH_L.decode(recognizer.predict(np.array([images9[i]]))[0]))\n",
        "      predicted_vector = finder.predict(np.array([images9[i]]))[0]\n",
        "    \n",
        "      ##### writer_network_spectar\n",
        "      if original_label == predicted_label:\n",
        "        writer_network_spectar[chr(predicted_label)].update_one(1)  # Network says predicted_label and its correct\n",
        "      else:\n",
        "        writer_network_spectar[chr(predicted_label)].update_one(0)  # Network says predicted_label and its wrong\n",
        "         \n",
        "      ##### writer_knn_spectar\n",
        "      min_labels = get_min_label(history, predicted_vector)\n",
        "      for k in ks:  # get min label is configured with respect to ks\n",
        "        min_label = min_labels[k]\n",
        "        if min_label is None:\n",
        "          min_label = predicted_label  # min label je moje predvidjanje \n",
        "        if min_label == original_label:  # min_label je ono sto ja predvidjam na onih 10%; to i evaluiram \n",
        "          writer_knn_spectars[k][chr(min_label)].update_one(1)\n",
        "        else:\n",
        "          writer_knn_spectars[k][chr(min_label)].update_one(0)\n",
        "  \n",
        "    #################################################### GET S AND S1\n",
        "    s = 0                  # tmp no of images on which knn is correct\n",
        "    s1 = 0                 # tmp no of images on which baseline is correct\n",
        "    sboth = 0              # tmp no of images on which either knn or baseline is correct\n",
        "    N = len(labels9[m:n])  # tmp no of evaluation images\n",
        "    for i in range(m, n): \n",
        "      original_label = int(labels9[i])\n",
        "      predicted_label = int(OH_L.decode(recognizer.predict(np.array([images9[i]]))[0])) # int(string like '48') -> ascii code 48\n",
        "      predicted_vector = finder.predict(np.array([images9[i]]))[0]\n",
        "    \n",
        "      ##### s1; old one\n",
        "      if predicted_label == original_label:\n",
        "        s1 += 1\n",
        "      predicted_label_bkp = predicted_label\n",
        "      ##### s; new approach\n",
        "      min_labels = get_min_label(history, predicted_vector)  # get list of predictions or each k\n",
        "      k = who_to_believe(predicted_label, writer_network_spectar, min_labels, writer_knn_spectars)  # Choose who have biggest mean of all spectars, use it as a aprediction\n",
        "      if k is not None and min_labels[k] is not None:  # believe to specific knn, which have it own prediction\n",
        "        predicted_label = min_labels[k]  # new approach; change network prediction if knn is sure enough  \n",
        "      if predicted_label == original_label:\n",
        "        s += 1\n",
        "  \n",
        "      ##### sboth\n",
        "      if predicted_label_bkp == original_label or (k is not None and min_labels[k] is not None and min_labels[k]==original_label):\n",
        "        sboth+=1 \n",
        "\n",
        "      ########## UPDATE history AND *spectar ##########\n",
        "      # original_label OK\n",
        "      predicted_label = predicted_label_bkp\n",
        "      # predicted_vector OK \n",
        "    \n",
        "      # history\n",
        "      predicted_vector_bkp = find_minimal(original_label, predicted_vector)  # smal bug; fixed; predicted vector is nearest cluster/avg of clusters not next tot last\n",
        "      if (predicted_label, original_label) not in history.keys():\n",
        "        history[(predicted_label, original_label)]=[predicted_vector_bkp, 1]\n",
        "      else:\n",
        "        history[(predicted_label, original_label)][0] = (history[(predicted_label, original_label)][0]*history[(predicted_label, original_label)][1]+predicted_vector_bkp)/(history[(predicted_label, original_label)][1]+1)\n",
        "        history[(predicted_label, original_label)][1] += 1\n",
        "    \n",
        "      # writer_network_spectar\n",
        "      if original_label == predicted_label:\n",
        "        writer_network_spectar[chr(predicted_label)].update_one(1)  # Network says predicted_label and its correct\n",
        "      else:\n",
        "        writer_network_spectar[chr(predicted_label)].update_one(0)  # Network says predicted_label and its wrong\n",
        "  \n",
        "      # writer_knn_spectar\n",
        "      min_labels = get_min_label(history, predicted_vector)  # prvo ga ubacim u istoriju - ali kao proseci itd. a onda kasnije trazim min_label; MOZDA INVERZNO? da ne bih nasao istog\n",
        "      for k in ks:\n",
        "        min_label = min_labels[k]\n",
        "        if min_label is None:\n",
        "          min_label = predicted_label  # min label je moje predvidjanje \n",
        "        if min_label == original_label:  # min_label je ono sto ja predvidjam na onih 10%; to i evaluiram \n",
        "          writer_knn_spectars[k][chr(min_label)].update_one(1)\n",
        "        else:\n",
        "          writer_knn_spectars[k][chr(min_label)].update_one(0)\n",
        "      ########## END UPDATE ##########        \n",
        "        \n",
        "        \n",
        "    S += s\n",
        "    S1 += s1\n",
        "    Sboth += sboth\n",
        "    Nall += N\n",
        "    del history\n",
        "    del writer_network_spectar\n",
        "    del writer_knn_spectars\n",
        "    # images9, labels9 = shuffle_both(images9, labels9)  # shuffle images for resampling; final 10% i use for evaluation, first 90% for dynamic history; DONT USE ANYMORE\n",
        "\n",
        "  #################################################### PRINT AND UPDATE GLOBAL VALUES\n",
        "  if S!=S1:  # Print only diff\n",
        "    print(\"Writer {0:4d} == mynew: {1:d} ({2:3.2f}%) == old: {3:d} ({4:3.2f}%) == both: {5:d} ({6:3.2f}%), No. of images {7:d}, len(image9)={8:d}\".format(writer, S, float(100*S)/Nall, S1, float(100*S1)/Nall, Sboth, float(100.0*Sboth)/Nall, Nall, n))\n",
        "  sumS += S\n",
        "  sumS1 += S1\n",
        "  sumSboth += Sboth\n",
        "  sumN += Nall\n",
        "  \n",
        "  if S==S1:     # Update win counts\n",
        "    equal += 1\n",
        "  elif S>S1:\n",
        "    winnew += 1\n",
        "    lenBetterNew += n\n",
        "  else:\n",
        "    winold += 1\n",
        "    lenBetterOld += n   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writer    1 == mynew: 378 (92.65%) == old: 367 (89.95%) == both: 385 (94.36%), No. of images 408, len(image9)=413\n",
            "Writer    2 == mynew: 358 (87.10%) == old: 338 (82.24%) == both: 365 (88.81%), No. of images 411, len(image9)=404\n",
            "Writer    3 == mynew: 367 (91.07%) == old: 336 (83.37%) == both: 370 (91.81%), No. of images 403, len(image9)=397\n",
            "Writer  518 == mynew: 396 (96.59%) == old: 360 (87.80%) == both: 398 (97.07%), No. of images 410, len(image9)=403\n",
            "Writer  519 == mynew: 352 (89.11%) == old: 343 (86.84%) == both: 357 (90.38%), No. of images 395, len(image9)=394\n",
            "Writer    8 == mynew: 372 (90.73%) == old: 363 (88.54%) == both: 385 (93.90%), No. of images 410, len(image9)=418\n",
            "Writer   10 == mynew: 401 (88.91%) == old: 384 (85.14%) == both: 410 (90.91%), No. of images 451, len(image9)=436\n",
            "Writer   11 == mynew: 381 (89.23%) == old: 376 (88.06%) == both: 388 (90.87%), No. of images 427, len(image9)=425\n",
            "Writer   17 == mynew: 375 (87.41%) == old: 374 (87.18%) == both: 384 (89.51%), No. of images 429, len(image9)=424\n",
            "Writer  530 == mynew: 369 (88.70%) == old: 361 (86.78%) == both: 381 (91.59%), No. of images 416, len(image9)=408\n",
            "Writer  534 == mynew: 366 (90.37%) == old: 362 (89.38%) == both: 377 (93.09%), No. of images 405, len(image9)=413\n",
            "Writer   23 == mynew: 391 (88.86%) == old: 387 (87.95%) == both: 408 (92.73%), No. of images 440, len(image9)=418\n",
            "Writer   27 == mynew: 359 (82.72%) == old: 348 (80.18%) == both: 367 (84.56%), No. of images 434, len(image9)=446\n",
            "Writer   28 == mynew: 355 (87.22%) == old: 359 (88.21%) == both: 370 (90.91%), No. of images 407, len(image9)=399\n",
            "Writer   31 == mynew: 340 (83.54%) == old: 323 (79.36%) == both: 345 (84.77%), No. of images 407, len(image9)=407\n",
            "Writer  547 == mynew: 379 (93.35%) == old: 352 (86.70%) == both: 382 (94.09%), No. of images 406, len(image9)=415\n",
            "Writer   35 == mynew: 369 (87.65%) == old: 348 (82.66%) == both: 374 (88.84%), No. of images 421, len(image9)=416\n",
            "Writer   37 == mynew: 354 (91.00%) == old: 355 (91.26%) == both: 355 (91.26%), No. of images 389, len(image9)=403\n",
            "Writer  554 == mynew: 358 (89.50%) == old: 350 (87.50%) == both: 361 (90.25%), No. of images 400, len(image9)=393\n",
            "Writer   46 == mynew: 381 (86.79%) == old: 367 (83.60%) == both: 390 (88.84%), No. of images 439, len(image9)=430\n",
            "Writer   47 == mynew: 369 (93.42%) == old: 351 (88.86%) == both: 378 (95.70%), No. of images 395, len(image9)=395\n",
            "Writer  559 == mynew: 366 (90.59%) == old: 356 (88.12%) == both: 372 (92.08%), No. of images 404, len(image9)=406\n",
            "Writer   49 == mynew: 345 (90.08%) == old: 311 (81.20%) == both: 351 (91.64%), No. of images 383, len(image9)=393\n",
            "Writer  562 == mynew: 362 (92.82%) == old: 347 (88.97%) == both: 363 (93.08%), No. of images 390, len(image9)=407\n",
            "Writer   51 == mynew: 349 (90.18%) == old: 344 (88.89%) == both: 355 (91.73%), No. of images 387, len(image9)=396\n",
            "Writer   54 == mynew: 391 (91.78%) == old: 394 (92.49%) == both: 399 (93.66%), No. of images 426, len(image9)=428\n",
            "Writer   62 == mynew: 334 (86.75%) == old: 339 (88.05%) == both: 347 (90.13%), No. of images 385, len(image9)=390\n",
            "Writer   63 == mynew: 371 (87.29%) == old: 361 (84.94%) == both: 388 (91.29%), No. of images 425, len(image9)=413\n",
            "Writer   66 == mynew: 365 (85.88%) == old: 362 (85.18%) == both: 372 (87.53%), No. of images 425, len(image9)=428\n",
            "Writer 1091 == mynew: 391 (93.32%) == old: 373 (89.02%) == both: 392 (93.56%), No. of images 419, len(image9)=411\n",
            "Writer   70 == mynew: 388 (90.87%) == old: 365 (85.48%) == both: 393 (92.04%), No. of images 427, len(image9)=433\n",
            "Writer   77 == mynew: 370 (91.58%) == old: 357 (88.37%) == both: 377 (93.32%), No. of images 404, len(image9)=409\n",
            "Writer  596 == mynew: 213 (53.65%) == old: 219 (55.16%) == both: 219 (55.16%), No. of images 397, len(image9)=393\n",
            "Writer  597 == mynew: 371 (91.83%) == old: 357 (88.37%) == both: 377 (93.32%), No. of images 404, len(image9)=398\n",
            "Writer 1112 == mynew: 356 (91.75%) == old: 360 (92.78%) == both: 362 (93.30%), No. of images 388, len(image9)=389\n",
            "Writer   90 == mynew: 367 (89.08%) == old: 353 (85.68%) == both: 373 (90.53%), No. of images 412, len(image9)=403\n",
            "Writer   94 == mynew: 359 (87.56%) == old: 347 (84.63%) == both: 371 (90.49%), No. of images 410, len(image9)=410\n",
            "Writer   95 == mynew: 347 (88.30%) == old: 335 (85.24%) == both: 354 (90.08%), No. of images 393, len(image9)=403\n",
            "Writer   96 == mynew: 375 (92.14%) == old: 365 (89.68%) == both: 381 (93.61%), No. of images 407, len(image9)=399\n",
            "Writer 1120 == mynew: 370 (93.20%) == old: 360 (90.68%) == both: 371 (93.45%), No. of images 397, len(image9)=400\n",
            "Writer   99 == mynew: 389 (88.41%) == old: 384 (87.27%) == both: 400 (90.91%), No. of images 440, len(image9)=423\n",
            "Writer  613 == mynew: 401 (92.18%) == old: 398 (91.49%) == both: 407 (93.56%), No. of images 435, len(image9)=416\n",
            "Writer  102 == mynew: 379 (90.24%) == old: 373 (88.81%) == both: 386 (91.90%), No. of images 420, len(image9)=416\n",
            "Writer  616 == mynew: 363 (92.13%) == old: 365 (92.64%) == both: 369 (93.65%), No. of images 394, len(image9)=403\n",
            "Writer  107 == mynew: 322 (86.79%) == old: 311 (83.83%) == both: 330 (88.95%), No. of images 371, len(image9)=391\n",
            "Writer  108 == mynew: 366 (87.98%) == old: 369 (88.70%) == both: 379 (91.11%), No. of images 416, len(image9)=414\n",
            "Writer  622 == mynew: 383 (94.80%) == old: 377 (93.32%) == both: 387 (95.79%), No. of images 404, len(image9)=410\n",
            "Writer  110 == mynew: 383 (88.45%) == old: 366 (84.53%) == both: 386 (89.15%), No. of images 433, len(image9)=426\n",
            "Writer  112 == mynew: 353 (91.21%) == old: 349 (90.18%) == both: 361 (93.28%), No. of images 387, len(image9)=396\n",
            "Writer  115 == mynew: 369 (86.62%) == old: 352 (82.63%) == both: 375 (88.03%), No. of images 426, len(image9)=421\n",
            "Writer  118 == mynew: 355 (85.34%) == old: 339 (81.49%) == both: 364 (87.50%), No. of images 416, len(image9)=408\n",
            "Writer  119 == mynew: 375 (87.01%) == old: 372 (86.31%) == both: 393 (91.18%), No. of images 431, len(image9)=437\n",
            "Writer  631 == mynew: 202 (53.87%) == old: 208 (55.47%) == both: 208 (55.47%), No. of images 375, len(image9)=389\n",
            "Writer  633 == mynew: 402 (93.49%) == old: 390 (90.70%) == both: 408 (94.88%), No. of images 430, len(image9)=413\n",
            "Writer  635 == mynew: 374 (91.67%) == old: 364 (89.22%) == both: 380 (93.14%), No. of images 408, len(image9)=395\n",
            "Writer  641 == mynew: 383 (92.51%) == old: 380 (91.79%) == both: 389 (93.96%), No. of images 414, len(image9)=396\n",
            "Writer  644 == mynew: 383 (89.07%) == old: 367 (85.35%) == both: 388 (90.23%), No. of images 430, len(image9)=436\n",
            "Writer  137 == mynew: 375 (94.46%) == old: 360 (90.68%) == both: 379 (95.47%), No. of images 397, len(image9)=395\n",
            "Writer  141 == mynew: 374 (92.57%) == old: 344 (85.15%) == both: 376 (93.07%), No. of images 404, len(image9)=390\n",
            "Writer  143 == mynew: 368 (90.20%) == old: 346 (84.80%) == both: 371 (90.93%), No. of images 408, len(image9)=395\n",
            "Writer  660 == mynew: 379 (93.12%) == old: 365 (89.68%) == both: 382 (93.86%), No. of images 407, len(image9)=396\n",
            "Writer  665 == mynew: 358 (91.56%) == old: 350 (89.51%) == both: 366 (93.61%), No. of images 391, len(image9)=390\n",
            "Writer  155 == mynew: 405 (89.40%) == old: 390 (86.09%) == both: 411 (90.73%), No. of images 453, len(image9)=442\n",
            "Writer  158 == mynew: 353 (90.28%) == old: 343 (87.72%) == both: 356 (91.05%), No. of images 391, len(image9)=390\n",
            "Writer  159 == mynew: 370 (92.27%) == old: 357 (89.03%) == both: 373 (93.02%), No. of images 401, len(image9)=396\n",
            "Writer  673 == mynew: 366 (91.50%) == old: 359 (89.75%) == both: 373 (93.25%), No. of images 400, len(image9)=399\n",
            "Writer  161 == mynew: 372 (89.00%) == old: 347 (83.01%) == both: 376 (89.95%), No. of images 418, len(image9)=415\n",
            "Writer  163 == mynew: 358 (87.96%) == old: 346 (85.01%) == both: 367 (90.17%), No. of images 407, len(image9)=404\n",
            "Writer  164 == mynew: 398 (91.71%) == old: 386 (88.94%) == both: 405 (93.32%), No. of images 434, len(image9)=430\n",
            "Writer  679 == mynew: 373 (93.95%) == old: 360 (90.68%) == both: 378 (95.21%), No. of images 397, len(image9)=415\n",
            "Writer  170 == mynew: 361 (91.16%) == old: 336 (84.85%) == both: 366 (92.42%), No. of images 396, len(image9)=389\n",
            "Writer  171 == mynew: 370 (91.36%) == old: 356 (87.90%) == both: 373 (92.10%), No. of images 405, len(image9)=394\n",
            "Writer  172 == mynew: 339 (83.70%) == old: 335 (82.72%) == both: 349 (86.17%), No. of images 405, len(image9)=411\n",
            "Writer  687 == mynew: 366 (91.96%) == old: 348 (87.44%) == both: 371 (93.22%), No. of images 398, len(image9)=392\n",
            "Writer  690 == mynew: 380 (92.91%) == old: 374 (91.44%) == both: 389 (95.11%), No. of images 409, len(image9)=407\n",
            "Writer  185 == mynew: 333 (82.43%) == old: 328 (81.19%) == both: 345 (85.40%), No. of images 404, len(image9)=394\n",
            "Writer  698 == mynew: 391 (93.76%) == old: 360 (86.33%) == both: 400 (95.92%), No. of images 417, len(image9)=415\n",
            "Writer  699 == mynew: 365 (89.68%) == old: 366 (89.93%) == both: 374 (91.89%), No. of images 407, len(image9)=401\n",
            "Writer  188 == mynew: 370 (91.13%) == old: 354 (87.19%) == both: 379 (93.35%), No. of images 406, len(image9)=401\n",
            "Writer  701 == mynew: 362 (87.65%) == old: 365 (88.38%) == both: 369 (89.35%), No. of images 413, len(image9)=392\n",
            "Writer  190 == mynew: 359 (86.51%) == old: 358 (86.27%) == both: 370 (89.16%), No. of images 415, len(image9)=428\n",
            "Writer  187 == mynew: 373 (88.18%) == old: 358 (84.63%) == both: 384 (90.78%), No. of images 423, len(image9)=414\n",
            "Writer  706 == mynew: 355 (90.10%) == old: 342 (86.80%) == both: 359 (91.12%), No. of images 394, len(image9)=403\n",
            "Writer  196 == mynew: 350 (86.85%) == old: 356 (88.34%) == both: 364 (90.32%), No. of images 403, len(image9)=401\n",
            "Writer  197 == mynew: 383 (93.64%) == old: 369 (90.22%) == both: 389 (95.11%), No. of images 409, len(image9)=416\n",
            "Writer  199 == mynew: 393 (87.72%) == old: 369 (82.37%) == both: 396 (88.39%), No. of images 448, len(image9)=433\n",
            "Writer  203 == mynew: 411 (92.57%) == old: 399 (89.86%) == both: 413 (93.02%), No. of images 444, len(image9)=426\n",
            "Writer  717 == mynew: 367 (94.83%) == old: 359 (92.76%) == both: 368 (95.09%), No. of images 387, len(image9)=391\n",
            "Writer  207 == mynew: 354 (89.39%) == old: 342 (86.36%) == both: 364 (91.92%), No. of images 396, len(image9)=391\n",
            "Writer  208 == mynew: 380 (92.68%) == old: 360 (87.80%) == both: 385 (93.90%), No. of images 410, len(image9)=413\n",
            "Writer 1233 == mynew: 374 (94.44%) == old: 368 (92.93%) == both: 377 (95.20%), No. of images 396, len(image9)=395\n",
            "Writer  211 == mynew: 391 (92.65%) == old: 387 (91.71%) == both: 392 (92.89%), No. of images 422, len(image9)=408\n",
            "Writer  219 == mynew: 357 (87.07%) == old: 350 (85.37%) == both: 366 (89.27%), No. of images 410, len(image9)=403\n",
            "Writer  224 == mynew: 362 (93.54%) == old: 340 (87.86%) == both: 365 (94.32%), No. of images 387, len(image9)=396\n",
            "Writer  743 == mynew: 369 (86.62%) == old: 374 (87.79%) == both: 385 (90.38%), No. of images 426, len(image9)=425\n",
            "Writer  745 == mynew: 348 (88.55%) == old: 349 (88.80%) == both: 352 (89.57%), No. of images 393, len(image9)=400\n",
            "Writer  750 == mynew: 380 (92.68%) == old: 372 (90.73%) == both: 388 (94.63%), No. of images 410, len(image9)=399\n",
            "Writer  751 == mynew: 356 (91.28%) == old: 324 (83.08%) == both: 358 (91.79%), No. of images 390, len(image9)=392\n",
            "Writer  240 == mynew: 342 (88.37%) == old: 330 (85.27%) == both: 342 (88.37%), No. of images 387, len(image9)=389\n",
            "Writer  243 == mynew: 350 (87.06%) == old: 340 (84.58%) == both: 361 (89.80%), No. of images 402, len(image9)=402\n",
            "Writer  242 == mynew: 373 (90.98%) == old: 353 (86.10%) == both: 380 (92.68%), No. of images 410, len(image9)=404\n",
            "Writer  246 == mynew: 384 (90.35%) == old: 381 (89.65%) == both: 385 (90.59%), No. of images 425, len(image9)=423\n",
            "Writer  252 == mynew: 342 (85.50%) == old: 337 (84.25%) == both: 351 (87.75%), No. of images 400, len(image9)=403\n",
            "Writer  765 == mynew: 354 (92.43%) == old: 338 (88.25%) == both: 356 (92.95%), No. of images 383, len(image9)=400\n",
            "Writer  254 == mynew: 379 (90.67%) == old: 374 (89.47%) == both: 385 (92.11%), No. of images 418, len(image9)=429\n",
            "Writer  255 == mynew: 359 (87.99%) == old: 340 (83.33%) == both: 369 (90.44%), No. of images 408, len(image9)=418\n",
            "Writer 1277 == mynew: 370 (92.73%) == old: 349 (87.47%) == both: 375 (93.98%), No. of images 399, len(image9)=399\n",
            "Writer 1282 == mynew: 363 (91.67%) == old: 344 (86.87%) == both: 365 (92.17%), No. of images 396, len(image9)=395\n",
            "Writer  258 == mynew: 355 (90.33%) == old: 347 (88.30%) == both: 370 (94.15%), No. of images 393, len(image9)=394\n",
            "Writer  261 == mynew: 539 (91.98%) == old: 525 (89.59%) == both: 540 (92.15%), No. of images 586, len(image9)=583\n",
            "Writer  267 == mynew: 326 (84.02%) == old: 316 (81.44%) == both: 341 (87.89%), No. of images 388, len(image9)=392\n",
            "Writer  271 == mynew: 344 (88.43%) == old: 343 (88.17%) == both: 351 (90.23%), No. of images 389, len(image9)=393\n",
            "Writer 1301 == mynew: 412 (93.42%) == old: 408 (92.52%) == both: 417 (94.56%), No. of images 441, len(image9)=435\n",
            "Writer  278 == mynew: 348 (86.14%) == old: 353 (87.38%) == both: 365 (90.35%), No. of images 404, len(image9)=397\n",
            "Writer  281 == mynew: 386 (93.69%) == old: 381 (92.48%) == both: 389 (94.42%), No. of images 412, len(image9)=424\n",
            "Writer  795 == mynew: 371 (93.45%) == old: 362 (91.18%) == both: 377 (94.96%), No. of images 397, len(image9)=395\n",
            "Writer  284 == mynew: 360 (87.38%) == old: 348 (84.47%) == both: 369 (89.56%), No. of images 412, len(image9)=405\n",
            "Writer  287 == mynew: 366 (92.66%) == old: 362 (91.65%) == both: 369 (93.42%), No. of images 395, len(image9)=401\n",
            "Writer  289 == mynew: 406 (84.58%) == old: 384 (80.00%) == both: 418 (87.08%), No. of images 480, len(image9)=464\n",
            "Writer  292 == mynew: 395 (87.20%) == old: 384 (84.77%) == both: 406 (89.62%), No. of images 453, len(image9)=442\n",
            "Writer  804 == mynew: 377 (91.95%) == old: 368 (89.76%) == both: 382 (93.17%), No. of images 410, len(image9)=408\n",
            "Writer  296 == mynew: 333 (91.48%) == old: 324 (89.01%) == both: 342 (93.96%), No. of images 364, len(image9)=397\n",
            "Writer  302 == mynew: 340 (86.08%) == old: 326 (82.53%) == both: 343 (86.84%), No. of images 395, len(image9)=399\n",
            "Writer  815 == mynew: 372 (94.18%) == old: 361 (91.39%) == both: 377 (95.44%), No. of images 395, len(image9)=407\n",
            "Writer  303 == mynew: 355 (89.42%) == old: 341 (85.89%) == both: 360 (90.68%), No. of images 397, len(image9)=394\n",
            "Writer  312 == mynew: 370 (86.45%) == old: 363 (84.81%) == both: 383 (89.49%), No. of images 428, len(image9)=416\n",
            "Writer  315 == mynew: 384 (90.78%) == old: 378 (89.36%) == both: 392 (92.67%), No. of images 423, len(image9)=425\n",
            "Writer  317 == mynew: 358 (86.06%) == old: 356 (85.58%) == both: 369 (88.70%), No. of images 416, len(image9)=420\n",
            "Writer  320 == mynew: 366 (85.92%) == old: 361 (84.74%) == both: 376 (88.26%), No. of images 426, len(image9)=426\n",
            "Writer  834 == mynew: 345 (88.24%) == old: 329 (84.14%) == both: 351 (89.77%), No. of images 391, len(image9)=397\n",
            "Writer  839 == mynew: 361 (89.58%) == old: 342 (84.86%) == both: 370 (91.81%), No. of images 403, len(image9)=391\n",
            "Writer  327 == mynew: 356 (88.12%) == old: 344 (85.15%) == both: 376 (93.07%), No. of images 404, len(image9)=403\n",
            "Writer  328 == mynew: 348 (84.88%) == old: 331 (80.73%) == both: 360 (87.80%), No. of images 410, len(image9)=411\n",
            "Writer  330 == mynew: 369 (88.70%) == old: 353 (84.86%) == both: 379 (91.11%), No. of images 416, len(image9)=417\n",
            "Writer  332 == mynew: 354 (89.62%) == old: 358 (90.63%) == both: 360 (91.14%), No. of images 395, len(image9)=392\n",
            "Writer  843 == mynew: 389 (92.40%) == old: 385 (91.45%) == both: 390 (92.64%), No. of images 421, len(image9)=414\n",
            "Writer  841 == mynew: 353 (89.14%) == old: 333 (84.09%) == both: 362 (91.41%), No. of images 396, len(image9)=389\n",
            "Writer  335 == mynew: 366 (84.72%) == old: 376 (87.04%) == both: 383 (88.66%), No. of images 432, len(image9)=427\n",
            "Writer  337 == mynew: 374 (89.69%) == old: 365 (87.53%) == both: 384 (92.09%), No. of images 417, len(image9)=435\n",
            "Writer  344 == mynew: 378 (90.43%) == old: 383 (91.63%) == both: 393 (94.02%), No. of images 418, len(image9)=427\n",
            "Writer  345 == mynew: 351 (90.23%) == old: 343 (88.17%) == both: 358 (92.03%), No. of images 389, len(image9)=389\n",
            "Writer 1369 == mynew: 385 (90.59%) == old: 371 (87.29%) == both: 397 (93.41%), No. of images 425, len(image9)=422\n",
            "Writer  347 == mynew: 362 (88.08%) == old: 367 (89.29%) == both: 368 (89.54%), No. of images 411, len(image9)=412\n",
            "Writer  860 == mynew: 357 (92.97%) == old: 325 (84.64%) == both: 362 (94.27%), No. of images 384, len(image9)=396\n",
            "Writer  865 == mynew: 359 (92.05%) == old: 349 (89.49%) == both: 364 (93.33%), No. of images 390, len(image9)=392\n",
            "Writer  359 == mynew: 364 (87.29%) == old: 354 (84.89%) == both: 375 (89.93%), No. of images 417, len(image9)=400\n",
            "Writer  360 == mynew: 388 (90.87%) == old: 378 (88.52%) == both: 399 (93.44%), No. of images 427, len(image9)=420\n",
            "Writer  361 == mynew: 383 (89.91%) == old: 359 (84.27%) == both: 387 (90.85%), No. of images 426, len(image9)=415\n",
            "Writer  874 == mynew: 354 (88.94%) == old: 368 (92.46%) == both: 373 (93.72%), No. of images 398, len(image9)=406\n",
            "Writer  876 == mynew: 347 (88.75%) == old: 344 (87.98%) == both: 355 (90.79%), No. of images 391, len(image9)=397\n",
            "Writer  877 == mynew: 362 (91.88%) == old: 350 (88.83%) == both: 369 (93.65%), No. of images 394, len(image9)=394\n",
            "Writer  887 == mynew: 372 (95.14%) == old: 363 (92.84%) == both: 381 (97.44%), No. of images 391, len(image9)=391\n",
            "Writer  379 == mynew: 377 (89.98%) == old: 369 (88.07%) == both: 387 (92.36%), No. of images 419, len(image9)=418\n",
            "Writer  896 == mynew: 365 (91.71%) == old: 356 (89.45%) == both: 366 (91.96%), No. of images 398, len(image9)=402\n",
            "Writer  902 == mynew: 363 (91.44%) == old: 358 (90.18%) == both: 373 (93.95%), No. of images 397, len(image9)=392\n",
            "Writer  392 == mynew: 371 (91.60%) == old: 358 (88.40%) == both: 375 (92.59%), No. of images 405, len(image9)=392\n",
            "Writer  395 == mynew: 385 (93.45%) == old: 379 (91.99%) == both: 388 (94.17%), No. of images 412, len(image9)=422\n",
            "Writer  399 == mynew: 345 (85.61%) == old: 339 (84.12%) == both: 348 (86.35%), No. of images 403, len(image9)=392\n",
            "Writer  401 == mynew: 379 (94.04%) == old: 375 (93.05%) == both: 382 (94.79%), No. of images 403, len(image9)=407\n",
            "Writer  914 == mynew: 387 (93.03%) == old: 383 (92.07%) == both: 389 (93.51%), No. of images 416, len(image9)=402\n",
            "Writer  402 == mynew: 350 (87.72%) == old: 344 (86.22%) == both: 361 (90.48%), No. of images 399, len(image9)=390\n",
            "Writer  403 == mynew: 340 (86.73%) == old: 330 (84.18%) == both: 349 (89.03%), No. of images 392, len(image9)=397\n",
            "Writer  919 == mynew: 347 (91.32%) == old: 342 (90.00%) == both: 350 (92.11%), No. of images 380, len(image9)=393\n",
            "Writer  409 == mynew: 374 (92.80%) == old: 362 (89.83%) == both: 380 (94.29%), No. of images 403, len(image9)=404\n",
            "Writer  931 == mynew: 368 (95.83%) == old: 353 (91.93%) == both: 370 (96.35%), No. of images 384, len(image9)=396\n",
            "Writer  938 == mynew: 362 (88.51%) == old: 358 (87.53%) == both: 376 (91.93%), No. of images 409, len(image9)=398\n",
            "Writer  431 == mynew: 347 (87.63%) == old: 351 (88.64%) == both: 354 (89.39%), No. of images 396, len(image9)=402\n",
            "Writer  943 == mynew: 338 (88.25%) == old: 337 (87.99%) == both: 346 (90.34%), No. of images 383, len(image9)=393\n",
            "Writer  951 == mynew: 360 (91.60%) == old: 338 (86.01%) == both: 365 (92.88%), No. of images 393, len(image9)=395\n",
            "Writer  443 == mynew: 389 (89.02%) == old: 386 (88.33%) == both: 403 (92.22%), No. of images 437, len(image9)=417\n",
            "Writer  444 == mynew: 362 (90.95%) == old: 355 (89.20%) == both: 375 (94.22%), No. of images 398, len(image9)=406\n",
            "Writer  445 == mynew: 361 (90.93%) == old: 348 (87.66%) == both: 376 (94.71%), No. of images 397, len(image9)=402\n",
            "Writer  446 == mynew: 347 (88.07%) == old: 355 (90.10%) == both: 355 (90.10%), No. of images 394, len(image9)=395\n",
            "Writer  961 == mynew: 359 (91.12%) == old: 343 (87.06%) == both: 367 (93.15%), No. of images 394, len(image9)=402\n",
            "Writer  451 == mynew: 418 (95.22%) == old: 401 (91.34%) == both: 419 (95.44%), No. of images 439, len(image9)=419\n",
            "Writer  453 == mynew: 357 (93.46%) == old: 351 (91.88%) == both: 357 (93.46%), No. of images 382, len(image9)=392\n",
            "Writer  458 == mynew: 359 (91.35%) == old: 352 (89.57%) == both: 362 (92.11%), No. of images 393, len(image9)=399\n",
            "Writer  461 == mynew: 365 (90.12%) == old: 347 (85.68%) == both: 373 (92.10%), No. of images 405, len(image9)=402\n",
            "Writer  465 == mynew: 382 (90.95%) == old: 360 (85.71%) == both: 389 (92.62%), No. of images 420, len(image9)=420\n",
            "Writer  466 == mynew: 361 (91.86%) == old: 360 (91.60%) == both: 364 (92.62%), No. of images 393, len(image9)=401\n",
            "Writer  468 == mynew: 356 (86.83%) == old: 359 (87.56%) == both: 364 (88.78%), No. of images 410, len(image9)=405\n",
            "Writer  472 == mynew: 365 (88.38%) == old: 354 (85.71%) == both: 375 (90.80%), No. of images 413, len(image9)=412\n",
            "Writer  473 == mynew: 350 (85.37%) == old: 347 (84.63%) == both: 361 (88.05%), No. of images 410, len(image9)=414\n",
            "Writer  477 == mynew: 347 (90.60%) == old: 340 (88.77%) == both: 349 (91.12%), No. of images 383, len(image9)=391\n",
            "Writer  989 == mynew: 380 (95.72%) == old: 355 (89.42%) == both: 384 (96.73%), No. of images 397, len(image9)=398\n",
            "Writer  991 == mynew: 341 (88.57%) == old: 322 (83.64%) == both: 346 (89.87%), No. of images 385, len(image9)=397\n",
            "Writer  481 == mynew: 369 (92.48%) == old: 342 (85.71%) == both: 372 (93.23%), No. of images 399, len(image9)=405\n",
            "Writer  996 == mynew: 409 (93.59%) == old: 386 (88.33%) == both: 416 (95.19%), No. of images 437, len(image9)=419\n",
            "Writer  494 == mynew: 335 (82.31%) == old: 324 (79.61%) == both: 358 (87.96%), No. of images 407, len(image9)=412\n",
            "Writer  495 == mynew: 391 (88.06%) == old: 395 (88.96%) == both: 405 (91.22%), No. of images 444, len(image9)=419\n",
            "Writer  502 == mynew: 345 (91.27%) == old: 336 (88.89%) == both: 351 (92.86%), No. of images 378, len(image9)=393\n",
            "CPU times: user 3h 25min 55s, sys: 10min 37s, total: 3h 36min 32s\n",
            "Wall time: 2h 55min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Fc4wfVXhwrz",
        "colab_type": "code",
        "outputId": "4b7f5874-e2b8-457a-a125-9c28142b8f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "print('winold: ', winold)\n",
        "print('equal: ', equal)\n",
        "print('winnew: ', winnew)\n",
        "print('S: (new): ', 100.0*sumS/sumN)\n",
        "print('S1: (old): ', 100.0*sumS1/sumN)\n",
        "print('Sboth: (new): ', 100.0*sumSboth/sumN)\n",
        "print('AVG len winold: ', 1.0*lenBetterOld/winold)\n",
        "print('AVG len winnew: ', 1.0*lenBetterNew/winnew)\n",
        "print('No of evaluation images: ', sumN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "winold:  24\n",
            "equal:  9\n",
            "winnew:  167\n",
            "S: (new):  89.60396645650977\n",
            "S1: (old):  87.24000734528984\n",
            "Sboth: (new):  91.42070147517904\n",
            "AVG len winold:  404.5416666666667\n",
            "AVG len winnew:  408.1736526946108\n",
            "No of evaluation images:  81685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "29a6KJhDomki",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# +2.36%/+4.18%"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}