\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2019

% ready for submission
% \usepackage{neurips_2019}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2019}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage[final]{neurips_2019}

% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2019}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{Learn the Way We Write: Automatic Adjustment of %offline 
Handwriting Neural Classifier to Individual Users}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Milan M.~Čugurović\thanks{poincare.matf.bg.ac.rs/$\sim$milan\_cugurovic} \\
  Department of Computer Science\\
  Faculty of Mathematics\\
  University of Belgrade\\
  Belgrade, 11000\\
  Serbia\\
  \texttt{milan\_cugurovic@math.rs} \\
  % examples of more authors
  \And
  Mladen Nikolić\thanks{poincare.matf.bg.ac.rs/$\sim$nikolic} \\
  Department of Computer Science\\
  Faculty of Mathematics\\
  University of Belgrade\\
  Belgrade, 11000\\
  Serbia\\
  \texttt{nikolic@math.rs}
  \And
  Novak Novaković \\
  Microsoft Development Center Serbia\\
  Belgrade, 11000\\
  Serbia\\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}

\maketitle

\begin{abstract}
  In this paper, we consider improving convolution neural network (CNN) classifier of offline handwritten text.  
  We focus on the style of handwriting each of the individual users, causing of its great variability and huge impact on the ability to successfully recognize written characters. 
  We present fast, scalable and a no-retrain method for improving CNNs classifier. 
  Using only basic machine learning techniques, such as K nearest neighbor classifier and K means clustering, we achieve up to +2.7\% improvement in neural classifier precision, and get state of the art results on the dataset we use. 
  We evaluate our method on two dataset: NIST Special Database 19 and ETH Zurich Deepwriting dataset. 
\end{abstract}

\section{Introduction}
The problem of automatic recognition of offline handwritten characters is a very practical problem, which is a part of the area of pattern recognition. 
Inspired by practical use, it develops both within academia as well as within the industrial sector. 
The industrial sector directly commercializes solutions of this problem by including them into devices like tablets, smartphones and the like. 
Cause of that it is very important to have precise classifiers that rarely make mistakes. 

The pioneering attempt to automatically recognize handwritten characters dates back to the 1950s \citet{leedham}. 
After this initial attempt a few a group of researchers worked independently on this problem \citet{plamondon}. 
Within the software and hardware limitations of that time, remarkable results were achieved. 
In the last ten years, the intensive development of neural networks has led to a shift in boundaries in many areas, 
including in the area of offline handwriting recognition. 
The results achieved by using convolutional neural networks exceeds the results of all methods developed up to then \citet{cnnbest1} \citet{cnnbest2} \citet{cnnbest3}. 

Although convolutional neural networks have significantly increased offline handwriting classification accuracy, there is still plenty of room for progress. 
In this paper, we presented fast, alphabet-independent and scalable method which improves pretrained CNN without its retraining.

%The new approach is based on the idea of knowing the character writing style each of the individual users and adjusting pretrained CNN to each of them. 
%Previous was accomplished by dynamic monitoring both of CNNs mistakes and successful predictions. 
%The main goal of this paper is to increase the precision of convolution neural networks created and trained for the purpose of classification of handwritten characters. 
%The improvement presented in this paper is based on the fact that handwriting style is something unique for each individual, or something that largely identifies it.
% The classifier improvement is based on the dynamic monitoring of both his mistakes and successful predictions. 

The new approach is based on the idea of knowing the character writing style each of the individual users. 
Presented improvement of pretrained offline handwriting CNN classifier is based on the dynamic monitoring both of his mistakes and successful predictions. 
By this monitoring, we created the so-called user writing history. 
Based on user writing history, a set of several models of KNN classifiers is formed, for different values of $K$ and the reliability of both the base classifier and these models is evaluated (in a principled way, which will be described later). 
Based on these ratings, method decide which one label to anticipate. 

In this paper, Section 2 describes work related to this problem while the proposed method is fully described in Section 3.
Section 4 provides experimental results, and conclusions are given in Section 5.

\section{Related work}
pass 

\subsection{Previous work in offline handwritten character recognition}
pass

\subsection{Previous work in improving offline handwriting classifiers}
pass

\section{Method}

This section describe the proposed method for improving the CNN classifier of offline handwritten text. 
Note that while the idea behind the learning users handwriting style is rather simple, because of the complexity of the proposed method, we first give it an overview. 

\subsection{Method overview}

The basic idea is to distinguish the reference modes %pattern
of writing for each character. 
This is motivated by the intuition that each character can be written in finite significantly different ways. 
Separation the different writing styles of each character was achieved by clustering. 
Thus, for each of the characters, several clusters were obtained representing aggregated different writing styles of that character. 
This tends to separate the different writing styles each of them. 

When proposed method is used, on application set, for each user a set of characters that he or she authored is divided into two sets: an adaptation set and test set. 
On adaptation set we detect the user's writing style by memorizing his individual characters writing patterns. 
On the test set, the proposed method makes predictions by taking into account the user's writing style. 

A sketch of the proposed method, which will be explained in more detail in the following sections, is given with: 
\begin{itemize}
  \item Images from the training set for the base classifier and validation set for the base classifier are grouped by labels (characters) and clustered within each group. 
  These clusters represent the main writing styles for each of the characters.
  \item For each author of the application set: 
  \begin{itemize}
    \item The set of his images is stratified into adaptation set and test set. 
    \item In the adaptation set, for each of the characters the most similar writing styles (from already defined writing styles) are being identified, which makes the author's writing history. 
    \item Alternative classifiers (K nearest neighbor method) and their confidence vectors are created on the adaptation set. 
    \item For every instance of test set (where proposed method is used):
      \begin{itemize}
        \item In addition to the base CNN prediction, alternative classifier predictions are also calculated.
        \item Based on the confidence vectors of all the classifiers, the prediction of the most reliable of them is selected. 
        \item For each classifier, using the correct and its predicted labels, its confidence vector is updated. 
      \end{itemize}
  \end{itemize}
\end{itemize}
A more detailed description of each step, as well as an explanation of terms such as writing history and the classifier confidence vector are given in more detail in the following sections. 


\subsection{Clustering individual character writing styles}
pass 

\subsection{Creating a writing history}
pass
%Možda zaista usvojiti naziv 'dynamic writing history' za istoriju pisanja?

\subsection{Using writing history}
pass

%\section{Implementation}
%pass

\section{Evaluation}
pass

\subsection{Used datasets}
pass

\subsubsection{NIST Special Database 19}
pass

\subsubsection{ETH Zurich Deepwriting Database}
pass

\subsection{Images preprocessing}
pass

\subsection{Datasets split}
pass

\subsubsection{NIST Special Database 19 split}
pass \citet{nist}

\subsubsection{ETH Zurich Deepwriting Database split}
pass \cite{deepwriting}

\subsection{Base CNN classificator}
pass

\subsubsection{Architecture}
pass 

\subsubsection{Training and results}
pass

\subsection{Evaluation results}
pass

\subsection{Comparison with relevant papers}
Ovo možda u related works?

\section{Conclusion}
pass 

\small

\begin{thebibliography}{99} 
  \bibitem[Patrick et al. (2016)]{nist} Patrick, Grother \ \&  Kayee, Hanaoka\ (2016) NIST Special Database 19 Handprinted Forms and Characters, 2nd Edition
  
  \bibitem[Aksan et al. (2018)]{deepwriting} Aksan, Emre \ \& Pece, Fabrizio \ \& Hilliges, Otmar\ (2018) DeepWriting: Making Digital Ink Editable via Deep Generative Modeling
  In {\itshape SIGCHI Conference on Human Factors in Computing Systems}: CHI '18, ACM, New York, NY, USA
  
  \bibitem[C.G. Leedham (1994)]{leedham} C.G. Leedham \ (1994) Historical perspectives of handwriting recognition systems 
  In {\itshape IEE Colloquium on Handwriting and Pen-Based Input}: 1-3
  
  \bibitem[Plamondon et al. (2000)]{plamondon} Plamondon, R., \ \& Srihari, S.N.\ (2000). 
  On-Line and Off-Line Handwriting Recognition: A Comprehensive Survey. IEEE Trans. Pattern Anal. Mach. Intell., 22, 63-84.

  \bibitem[Srihari et al. (2006)]{cnnbest1} Srihari, Sargur N., \& Xuanshen Yang \& and Gregory R. Ball. \ (2006) “Offline Chinese Handwriting Recognition : A Survey.”

  \bibitem[Pavarez et al. (2013)]{cnnbest2} Parvez, Mohammad \&  Mahmoud, Sabri. \ (2013). Offline Arabic Handwritten Text Recognition: A Survey. ACM Computing Surveys (CSUR). 45. 10.1145/2431211.2431222. 

  \bibitem[Awaida et al. (2012)]{cnnbest3} Awaida, Sameh \& Mahmoud, Sabri. \ (2012). State of the art in off-line writer identification of handwritten text and survey of writer identification of Arabic text. Educational Research and Reviews. 7. 10.5897/ERR11.303. 
\end{thebibliography}


\end{document}